
[{"content":"you have found my website somehow\nyou can find out more about me in the about section\nthere is the now section for my current life in progress\n","date":"2024-04-29","externalUrl":null,"permalink":"/","section":"","summary":"you have found my website somehow","title":"","type":"page"},{"content":"","date":"2024-04-29","externalUrl":null,"permalink":"/posts/","section":"Posts","summary":"","title":"Posts","type":"posts"},{"content":"","date":"2024-03-31","externalUrl":null,"permalink":"/tags/gnu/linux/","section":"Tags","summary":"","title":"Gnu/Linux","type":"tags"},{"content":" getting hands on maas using qemu/kvm\n\u0026amp;\u0026amp; last remaining brain cells introduction # i wanted to get my hands on maas \u0026amp;\u0026amp; overall devops operations for a while now\ni\u0026rsquo;ve decided to start by taking a look at maas on my local machine using qemu/kvm\nmaas? # maas metal as a service is canonical open source solution for bare-metal server deployment \u0026amp;\u0026amp; management for cloud-like environment\nyou oftenly use maas to orchestrate your bare-metal hosts (mini pcs, servers\u0026hellip;) to deploy your os \u0026amp;\u0026amp; manage your hosts from the network, w/out feeling like moving your chair\njokes aside, it is a very cool way to manage your hosts without custom made or integrated ipam solutions (idrac, ilo\u0026hellip;) remotely\nit is a standalone pxe/preseed service to streamline machines management -\u0026gt; you typically boot over the network \u0026amp;\u0026amp; your host appears onto your controller ready to be managed\nbig plus for me is its web ui, possible rest api calls \u0026amp;\u0026amp; its cli management\ntechnical terms # maas refers your hosts as nodes\nthese nodes are part of zones, simple organisational units that contains nodes, where each node is in one, \u0026amp;\u0026amp; only one zone (\u0026ldquo;bedroom\u0026rdquo;, \u0026ldquo;closet\u0026rdquo;, whatever\u0026hellip;)\nnewly installed maas comes with the \u0026ldquo;default\u0026rdquo; zone which contains all nodes unless you create a new one\nthose zones are part of regions, same purpose as zones are for nodes, but for zones\nsome particular nodes will be controllers, especially regions controllers \u0026amp;\u0026amp; racks controllers\nregion controllers deals w/ your requests, when rack controllers provide the resulting actions to the asked nodes\nkeep in mind that region controllers (for regions, obviously) are the entry points for your actions \u0026amp;\u0026amp; rack controllers are the front-line managers for your nodes\nregions controllers typically has the web ui, the rest api, the database \u0026amp;\u0026amp; such, where the racks controllers manage the nodes by implementing dhcp, giving orders, hosting images\u0026hellip;\na node will be going through different commissioning states, such as \u0026ldquo;New\u0026rdquo;, \u0026ldquo;Commissioning\u0026rdquo;, \u0026amp;\u0026amp; \u0026ldquo;Ready\u0026rdquo;\na full glossary is available on maas.io docs but i wanted to put my words on important notions i use later\nthe plan # i will be provisioning two vms, could be considered as bare-metal servers here, from a controller that will be a region \u0026amp;\u0026amp; a rack one\nhere is a simplified diagram of what my installation will look like\n%%{init: {'theme':'dark'}}%% graph TD subgraph hosted-network nat-gateway(nat-gateway\n192.168.122.1) end subgraph maas-network maas-controller(maas-controller\n192.168.122.2\n172.16.0.10) maas-node-001[maas-node-001\n172.16.0.2] maas-node-002[maas-node-002\n172.16.0.3] end nat-gateway ---|natting| maas-controller maas-controller --- maas-node-001 \u0026 maas-node-002 the maas-controller will do both region \u0026amp;\u0026amp; rack controller, distributing ip addresses through dhcp, be the dns, gateway \u0026amp;\u0026amp; have a web ui\nfor a more corporate use, you can use your own dhcp server from your router e.g. pfsense, just make sure you configure \u0026ldquo;tftp\u0026rdquo; \u0026amp;\u0026amp; \u0026ldquo;network booting\u0026rdquo; values to redirect your nodes on your maas controller when booting over the network\ngetting started # i will use virt-manager as my virtualisation tool, i could have use usual qemu-img \u0026amp;\u0026amp; qemu-system-x86_64 commands but that could have lead to more complex comprehension\nubuntu server 22.04 lts will be my choice to host the controller\ni will show you the process after you have installed an ubuntu server vm\nmy controller will have 2 vcpu, 4 gb ram \u0026amp;\u0026amp; 16 gb virtio storage, where my nodes will have 4 vcpu, 8 gb ram \u0026amp;\u0026amp; 32 gb\ni will provision ubuntu desktop 22.04 lts on maas-node-001 \u0026amp;\u0026amp; maas-node-002\nmy boot order: 1. over the network, 2. on the hard drive\ncontroller vm config # the maas-controller vm has two network interfaces, the first for the maas-network \u0026amp;\u0026amp; the other for the hosted-network\nin this first configuration, i will configure ssh root access using ssh keys\nlater on, i will use the same ssh keys to connect to my nodes, during the controller installation i will show you how to use different ones if you want to\non the installed ubuntu server, i will accept temporarly password based ssh connection for root user to transit the public key\nstarting by changing root password, verifying it\nsudo passwd root # changing root user password su - # checking it modifying /etc/ssh/sshd_config to accept password based authentication on root user \u0026amp;\u0026amp; restarting service to make it take effect\nnano /etc/ssh/sshd_config \u0026amp;\u0026amp; systemctl restart sshd 30 31 32 33 34 35 36 # Authentication #LoginGraceTime 2m PermitRootLogin yes #StrictModes yes #MaxAuthTries 6 #MaxSessions 10 after that, on any host over 192.168.122.0/24 network, i generate ssh keys pair to apply them later\ni remove the known fingerprint if i have already connected once to another machine using this ip address \u0026amp;\u0026amp; generating the keys using ed25519 algorithm, w/out passphrase\nsed -i \u0026#39;/192.168.122.2/d\u0026#39; ~/.ssh/known_hosts # fingerprint... ssh-keygen -t ed25519 -N \u0026#34;\u0026#34; -f \u0026#34;$HOME/.ssh/maas-global\u0026#34; here my private key is ~/.ssh/maas-global \u0026amp;\u0026amp; my public key is ~/.ssh/maas-global.pub\nsending the ssh public key on the remote host\n(remote root password asked)\nssh-copy-id -i .ssh/maas-global.pub root@192.168.122.2 for more simplicity, i will add on my ~/.ssh/config an entry to tell: when i type ssh maas-controller, you do ssh root@192.168.122.2 using the private key generated\nnano ~/.ssh/config 64 65 66 67 68 69 # maas-controller host maas-controller hostname 192.168.122.2 user root preferredauthentications publickey identityfile ~/.ssh/maas-global we can now login onto the maas-controller vm \u0026amp;\u0026amp; remove password based authentication for root user\nssh maas-controller nano /etc/ssh/sshd_config \u0026amp;\u0026amp; systemctl restart sshd 30 31 32 33 34 35 36 # Authentication #LoginGraceTime 2m PermitRootLogin prohibit-password #StrictModes yes #MaxAuthTries 6 #MaxSessions 10 maas installation # at this point, you should have a ubuntu server vm, ssh root accessible, w/ your network interfaces configured (netplan)\nmaas can be installed using apt or snap package managers, although i\u0026rsquo;m not familiar w/ snap, i\u0026rsquo;ll use it since maas is most working on it\nthe latest stable maas version available as i\u0026rsquo;m writing this post is 3.5, you can see what\u0026rsquo;s yours using\nsnap info maas | grep latest here is my output\ntracking: latest/edge\nlatest/stable: \u0026ndash; latest/candidate: \u0026ndash; latest/beta: \u0026ndash; latest/edge: 3.5.0~beta1-16547-g.bcbb6120f 2024-03-30 (34542)\nif you remove the pipe, you will see all the available releases\nnote that the – is for \u0026ldquo;there is not\u0026rdquo;, \u0026amp;\u0026amp; the ↑ symbols are pointers for the above\ne.g.\n3.4/stable: 3.4.1-14343-g.a552d2522\n3.4/candidate: ↑ 3.4/beta: ↑\n3.4/beta, stable \u0026amp;\u0026amp; candidatate are all aliases for 3.4.1-14343-g.a552d2522\nw/ that said, i installed the latest release\nsnap install --channel=latest/edge maas after that, some ports should be exposed by maas\nmaas needs a database to work, even though you have a snap package for a non-production ready testing database maas-test-db\ni\u0026rsquo;ll install a new postgresql db for maas\nfirst, i export the variables i\u0026rsquo;ll use for my commands\nexport MAAS_DBADDRESS=\u0026#34;127.0.0.1\u0026#34; export MAAS_DBUSER=maas-db-user export MAAS_DBPASS=maas-db-password export MAAS_DBNAME=maas-psql-db export MAAS_USER=xeylou export MAAS_USEREMAIL=xeylou@proton.me feel free to modify yours as you like\nthen i install postgresql\napt install -y postgresql i will create a simple postgre user for the database connections using $MAAS_DBUSER \u0026amp;\u0026amp; $MAAS_DBPASS\nsudo -i -u postgres psql -c \u0026#34;CREATE USER \\\u0026#34;$MAAS_DBUSER\\\u0026#34; WITH ENCRYPTED PASSWORD \u0026#39;$MAAS_DBPASS\u0026#39;\u0026#34; then i create a database associated w/ this user\nsudo -i -u postgres createdb -O \u0026#34;$MAAS_DBUSER\u0026#34; \u0026#34;$MAAS_DBNAME\u0026#34; \u0026amp;\u0026amp; the most complicate part (yes, it was), creating a line for this newly created db\necho \u0026#34;host $MAAS_DBNAME $MAAS_DBUSER 0/0 md5\u0026#34; \u0026gt;\u0026gt; /etc/postgresql/14/main/pg_hba.conf \u0026amp;\u0026amp; you are basically done w/ the database configuration\nnow, as i said before, i\u0026rsquo;ll configure my maas controller as a region controller \u0026amp;\u0026amp; a rack controller\nin that process, i\u0026rsquo;ll also tell the maas command line to use the postgre db\n(keep the maas web ui url prompted by pressing enter or change it at this step)\nmaas init region+rack --database-uri \u0026#34;postgres://$MAAS_DBUSER:$MAAS_DBPASS@$MAAS_DBADDRESS/$MAAS_DBNAME\u0026#34; once you are done, your maas controller is installed\nyou only need to create an admin user to log into the web ui, use the rest api\u0026hellip; \u0026amp;\u0026amp; such\n(enter a password twice, then press enter to skip importation)\nmaas createadmin --username=$MAAS_USER --email=$MAAS_USEREMAIL you can resume the installation on the web ui or continue using commands\ni\u0026rsquo;ll show you both, starting w/ the web ui, http://192.168.122.2:5240/MAAS in my case\nNote click on the images to extend them, next time i\u0026rsquo;ll zoom more when i do captures\u0026hellip; (login w/ your admin user $MAAS_USER \u0026amp;\u0026amp; its password created above)\nhere you can change the region name of your controller, \u0026amp;\u0026amp; also configure dns fowarders if you plan to use your controller as nodes dns (for custom records)\nthen, it\u0026rsquo;ll take you to the images settings, where you can download ubuntu or centos images for your nodes\nby default it\u0026rsquo;ll download the ubuntu 20.04 image automatically \u0026amp;\u0026amp; you\u0026rsquo;ll not able to delete it unless you change the \u0026ldquo;default image\u0026rdquo; in the settings\u0026hellip;\nleave it as it is or download new images, as you wish\nyepee\nnow, it\u0026rsquo;s time to import a ssh public key to add to the nodes after they\u0026rsquo;ll get deployed, in order to ssh into them securely\ni used the same one as the maas controller, but you can an other one if you want to\n\u0026amp;\u0026amp; you are done w/ the maas (basic) installation\nto do everything i showed using commands\n(note that i connect to the maas api using the maas login command to do modifications)\nexport MASS_URL=http://192.168.122.2:5240/MAAS export SSH_PUB_KEY=\u0026#34;ssh-ed25519 YOUR_SSH_PUB_KEY user@hostname\u0026#34; maas apikey --username=$MAAS_USER \u0026gt; $MAAS_USER-api-key-file export MAAS_API_KEY=$(cat $MAAS_USER-api-key-file) maas login $MAAS_USER $MASS_URL $MAAS_API_KEY maas $MAAS_USER maas set-config name=upstream_dns value=\u0026#34;8.8.8.8\u0026#34; maas $MAAS_USER sshkeys create \u0026#34;key=$SSH_PUB_KEY\u0026#34; subnet configuration # for my use case, i configured the maas controller to be a dhcp server for my maas-network\ngoing to the Subnets sections, i modified the 172.16.0.0/16 one\n(clicked on 172.16.0.0/16)\ni edited it to add a Gateway \u0026amp;\u0026amp; a DNS for the hosts (the controller, 172.17.0.10); these infos are distributed by your controller when your nodes ask for leases\ni also Reserve a dynamic range for commissioning (172.16.0.20 -\u0026gt; 172.16.0.30)\n(see below)\nto start the dhcp, go back on the Subnets section \u0026amp;\u0026amp; go on Untagged on your desire fabric (nics for ubuntu\u0026hellip; here i clicked on untagged for fabric-0)\nthen Configure DHCP\nchoose the only rack controller you have, \u0026amp;\u0026amp; that is done\ncommissionning process # i created a vm on the maas-network, only booting over the network\nit gets an ip address by the controller dhcp \u0026amp;\u0026amp; then boot over the given image, here ubuntu 22.04 bc i changed it\nafter a few minutes, the vm showed up on the Machines section, we still need to commission it \u0026amp;\u0026amp; deploy an image\nbut i got a problem, maas refused to provision it unless i chose a way to power it (ilo, idrac, pdu\u0026hellip;) because it detects \u0026amp;\u0026amp; manages it\nsince i don\u0026rsquo;t have any other solutions than shutting down the vm for now\n(i didn\u0026rsquo;t want to take time to check for virsh integration\u0026hellip; although it is possible) i selected Manual\nthen, maas started commissionning it\na few seconds later, it showed up as ready\nso i started Deploy it\nafter few minutes, the node was provisioned\n(don\u0026rsquo;t mind the \u0026ldquo;Failed testing\u0026rdquo;, i was messing arround, yours will be fine w/ your ubuntu version on it)\nit has a question mark on power because he has no clue if it is powered on or not since he can\u0026rsquo;t control/check its alimentation\ni added an entry on my ~/.ssh/config for maas-node-001 like i did for the controller to access it more easily over ssh\n(change your identityfile if you have configured your $MAAS_USER to use a different ssh key pair than the controller in the installation process)\n71 72 73 74 75 76 # maas-node-001 host maas-node-001 hostname 172.16.0.2 user ubuntu preferredauthentications publickey identityfile ~/.ssh/maas-global then, you can use your maas-controller as an ssh proxy to access your maas-node-001\n(because you are not in the same network)\nNote if you don\u0026rsquo;t understand well what ssh proxies are, or you want to discover more about it, they are in my ssh cheat-sheet ssh -J maas-controller maas-node-001 or, if you want to, you can specify the proxy in the ~/.ssh/config, \u0026amp;\u0026amp; then just do ssh maas-node-001\n71 72 73 74 75 76 77 # maas-node-001 host maas-node-001 hostname 172.16.0.2 user ubuntu preferredauthentications publickey identityfile ~/.ssh/maas-global proxyjump maas-controller ssh maas-node-001 you can now manage your servers, deploying images \u0026amp;\u0026amp; such, calling it through api or cli like i did for the installation above etc.\nyou still need few other steps to get all things done (Internet access, ntp\u0026hellip;)\nbut if you have encountered errors or misunderstandings, i am here to answer your questions on discord or email\n(i\u0026rsquo;m not a maas expert, i\u0026rsquo;d be extremely grateful if you also consider dm me to explain that i\u0026rsquo;m wrong)\nfinal step # maas use a different ntp client than the one shipped w/ ubuntu, chrony over systemd-timesyncd\ncanonical recommend disabling timesync to avoid ntp client conflicts, such as synchronisation issues\nsystemctl disable --now systemd-timesyncd on the network side, your nodes can only use their local network, their local dns \u0026amp;\u0026amp; other stuff like accessing the outside w/ apt\nping 172.16.0.10 # nodes can ping their gateway dig maas-controller.maas # nodes can resolve dig google.com # nodes can resolve but they cannot access the Internet yet, because you need to nat their addresses\nto do so, you need a dynamic nat or a static nat (dynamic to access the outside temporarly, static to permanently translate an outside address for your node to your node inside ip address in your maas-network)\notherwise, nodes will not be able to ping the outside or such\nusing virt-manager, you can use the nat bridge\nif you are not using libvirt, you can manually add the nat rules using iptables \u0026amp;\u0026amp; ip forward\nyou first need to enable ip forward (moving packets from an interface to an other, like a router)\napt install -y iptables-persistent echo \u0026#39;net.ipv4.ip_forward=1\u0026#39; \u0026gt;\u0026gt; /etc/sysctl.conf \u0026amp;\u0026amp; sysctl -p /etc/sysctl.conf then, you can translate private ip addresses (on maas-network) over ones on your hosted-network \u0026amp;\u0026amp; do the translation (nat network address translation)\n(where enp2s0 is your interface on 192.168.122.0/24)\ndynamic nat:\niptables -t nat -A POSTROUTING -o enp2s0 -j MASQUERADE you can also permanently translate an external address (here 192.168.122.3) to your local node on 172.16.0.2\nusefull to host websites, services\u0026hellip; doing static nat\nstatic nat:\niptables -t nat -A PREROUTING -i enp2s0 -j DNAT -d 192.168.122.3 --to 172.16.0.2 iptables -t nat -A POSTROUTING -o enp1s0 -j SNAT -s 172.16.0.2 --to 192.168.122.3 now, you can ping google.com or whatever you need\niptables can be used in a much more complex way, i prefered keep it simple\nyou can think about it when you\u0026rsquo;ll want to authorise natting for certain addresses only etc.\nthank you for reading, sincerely, have a good day!\n","date":"2024-03-31","externalUrl":null,"permalink":"/posts/hands-on-maas/","section":"Posts","summary":"getting hands on maas using qemu/kvm","title":"hands on maas","type":"posts"},{"content":"","date":"2024-03-31","externalUrl":null,"permalink":"/tags/","section":"Tags","summary":"","title":"Tags","type":"tags"},{"content":"","date":"2024-03-31","externalUrl":null,"permalink":"/tags/virtualization/","section":"Tags","summary":"","title":"Virtualization","type":"tags"},{"content":" Skills # my interests are oriented in networks \u0026amp; telecommunications, enjoying learning new technos on bare metal, using embedded or virtualization (gns3, packet tracer)\ni\u0026rsquo;ve been a linux enthusiast for years, having over 3 years of gnu/linux layer 2-7 administration of various distributions for daily use (rhel, debian, alpine, arch, nixos)\ni have a strong background in virtualization \u0026amp; containerization using qemu/kvm, proxmox, esxi, gns3, cisco pt, docker + compose \u0026amp; k8s\ni also love programming using java, python \u0026amp; bash\nStudy # i have a French high-school bachelor general degree in mathematics \u0026amp; computer science\ni am a second-year student at University of Pau and the Adour Region\nHobbies # i like learning as much as i can about everything\ni am an IT privacy \u0026amp; security enthusiast\n","date":"2024-03-02","externalUrl":null,"permalink":"/about/","section":"","summary":"Skills # my interests are oriented in networks \u0026amp; telecommunications, enjoying learning new technos on bare metal, using embedded or virtualization (gns3, packet tracer)","title":"About","type":"page"},{"content":"","date":"2024-02-07","externalUrl":null,"permalink":"/tags/docker/","section":"Tags","summary":"","title":"Docker","type":"tags"},{"content":"","date":"2024-02-07","externalUrl":null,"permalink":"/tags/windows/","section":"Tags","summary":"","title":"Windows","type":"tags"},{"content":" discovering windows images\ncontainerazation and its use cases introduction # i daily use docker at work \u0026amp;\u0026amp; for personal use to host \u0026amp;\u0026amp; deploy services quickly\nto me, docker permits fast service deployment \u0026amp;\u0026amp; management w/ docker compose || docker file\u0026hellip;, ha w/ docker swarm || kubernetes (k8s, k3s, k0s, k8e\u0026hellip;) \u0026amp;\u0026amp; more\nin that way, i recently discovered that windows could be containerized, thanks to this video \u0026amp;\u0026amp; the work of dockur\nso i wanted to dig into what windows images containerization currently looks like, \u0026amp;\u0026amp; if its keep the same properties as usual docker containerization such as replication, fast deployment, ease of use, on demand scaling etc.\nwhy containerize windows # i think containerizing windows would give you the flexibility that docker has over services\nthat means you could easily replicate a configuration, a volume\u0026hellip; as long as windows permits it (more on that later)\nyou could also manage your infrastructure only using docker, thus is a free \u0026amp;\u0026amp; widely used tool - no more windows proprietary integrations or limitating corporate windows integrated solutions etc.\nmore on that, windows could be inside your docker installation : using same docker networks, sharing services\u0026hellip; to averall take the avantages of the docker management \u0026amp;\u0026amp; integrate it to a windows environnement\nif i go beyond what i saw previously, i\u0026rsquo;d say that i wish to see micro-services hosted on windows containerized environments (active directories, exchange servers\u0026hellip;)\nalso, as far as my windows knowledge goes, i didn\u0026rsquo;t heard of a movement of windows moving forward docker integration\nhow does it work # i\u0026rsquo;ll only talk about dockur work here, since it is the biggest windows containerization project i know\nso what they\u0026rsquo;ve done, is using docker as a launching platform for kvm based virtualization to launch windows 11, 10 etc. images\nto start, all of their integration is comming from an existing project aiming to bring qemu into a docker container, qemux/qemu-docker (based on their Dockerfile)\n1 2 3 4 5 6 7 8 FROM scratch COPY --from=qemux/qemu-docker:4.15 / / ARG DEBCONF_NOWARNINGS=\u0026#34;yes\u0026#34; ARG DEBIAN_FRONTEND \u0026#34;noninteractive\u0026#34; ARG DEBCONF_NONINTERACTIVE_SEEN \u0026#34;true\u0026#34; # [...] that include the kvm acceleration, *.iso importation, as well as the web-based viewer\u0026hellip;\nin fact, thanks to qemux, it has usb/disks pass-through, network integration, support for custom *.iso images, support for docker volumes etc.\nafter that, it turns to be shell scripts to run qemu commands \u0026amp;\u0026amp; instruct a virtual machine on your host (exiting docker)\nstill docker related? # in some terms, you still use docker to manage your environment; but in fact, you are exiting it to bring up commands to run a vm\nto me it is still docker related for the management part (you can share disks from docker instructions, share drives, vertically scale\u0026hellip;)\nbut from a hardware view, it has nothing to do w/ docker, only qemu/kvm\nmy point of view # this kind of project is very very new (two months for dockur \u0026amp;\u0026amp; 10 months for qemux)\n\u0026amp;\u0026amp; as i recall, to the public crowd as i am in, it didn\u0026rsquo;t get that much noise, whereas i\u0026rsquo;m a tech enthousiast \u0026amp;\u0026amp; neither me or my friends have heard of it\ni think it\u0026rsquo;s safe for now to test it || watch it grow rather than deploy it (not production tested, support?, only docker community?, microsoft reaction)\ni think it is a good way to bypass windows restrictions \u0026amp;\u0026amp; get a new way to host windows only services; \u0026amp;\u0026amp; also integrated it well better w/ your existing docker infrastructure\ni hope these projects go well near future, i\u0026rsquo;ll keep watching them \u0026amp;\u0026amp; support them\n","date":"2024-02-07","externalUrl":null,"permalink":"/posts/windows-container/","section":"Posts","summary":"discovering windows images","title":"windows containers","type":"posts"},{"content":"","date":"2023-12-23","externalUrl":null,"permalink":"/tags/thoughts/","section":"Tags","summary":"","title":"Thoughts","type":"tags"},{"content":" writing some thoughts,\nmainly about work introduction # FR : j\u0026rsquo;expose quelques pensées que j\u0026rsquo;ai pu avoir sur ma manière de travailler ces derniers temps, si cela peut aider des gens\nj\u0026rsquo;écrirai avec des majuscules en début de phrases pour que ce soit plus agréable à lire, un prologue en anglais sera présent au début des parties pour résumer le raisonnement\nEN: i wanted to write some thoughts i had on working nowadays, if it can helps\ni\u0026rsquo;ll write w/ capital letters at the beginning of my sentences (i usually don\u0026rsquo;t) to make it more readable, an english prologue will be at the beginning of each thoughts\nhourly income # Hourly income punishes people that are working fast. People that works great charge by the project, not by the time they took it done. Because if you charge by the hour, you get punished for doing well.\nYou are also incentivized to lie about your time, \u0026amp; you get punished by your salary if you done things quickly or efficiently. Hourly income doesn\u0026rsquo;t make sense for those who works great.\nLes personnes compétentes se font avoir si elles sont payées à l\u0026rsquo;heure. Leur salaire est proportionnel au temps qu\u0026rsquo;elles mettent à faire leur travail, pas à sa valeur.\nLes gens excessivement bons dans leur domaine travailleront mieux \u0026amp;\u0026amp; finiront peut-être un projet plus rapidement que d\u0026rsquo;autres moins compétents. Mais ils finiront par être moins payés parce qu\u0026rsquo;ils l\u0026rsquo;auront terminé plus rapidement : ces gens auront mis moins de temps à faire leur travail qu\u0026rsquo;une personne moins compétente - mais qui sera payée plus pour la même tâche qu\u0026rsquo;elle aura pris plus de temps à faire.\nQuand une personnes est payée à l\u0026rsquo;heure, elle tend aussi à rallonger son temps de travail pour valoriser son salaire, qui est définit par le temps qu\u0026rsquo;elle y consacre. Le temps pris est valorisé à la qualité du travail : au plus on met du temps à faire notre travail (moins on en fait), au plus on est rémunéré.\nLes personnes compétentes, qui travaillent plus vite que les personnes normales pour la même tâche finissent par être les moins bien payées pour la même activité. Si vous rallongez votre travail, vous êtes payés plus; si vous travaillez mieux, vous êtes payés moins.\nUn salaire à l\u0026rsquo;heure n\u0026rsquo;est pas intéressant pour une personne qui travaille bien.\nHourly income doesn\u0026rsquo;t make sense for those who works great.\nSi tu es payé à l\u0026rsquo;heure, tu es puni si tu travailles bien.\nIf you charge by the hour, you get punished for doing well.\nsi je sors de mon \u0026ldquo;one sided view\u0026rdquo;, c\u0026rsquo;est aussi bien dans une entreprise d\u0026rsquo;être payé à l\u0026rsquo;heure comme les autres : pour ne pas créer de rivalités entre qui est payé le plus\nc\u0026rsquo;est aussi à la responsabilité de l\u0026rsquo;employeur qui t\u0026rsquo;a payé à l\u0026rsquo;heure de savoir s\u0026rsquo;il aurait du te payer au projet || non, e.g. en freelance (je ne voulais pas que toucher au domaine salarial)\n\u0026ldquo;tu auras peut-être une version différente de ton discours quand tu auras des enfants\u0026rdquo;, merci, || quand j\u0026rsquo;aurai une vision différente du travail peut-être, parce que je souhaiterais peut-être mieux valoriser mon temps, || autre\u0026hellip;\nnever-ending-projects # There is a better possible version of everything that has ever existed, like, ever.\nI learned it\u0026rsquo;s nealy impossible to finish a personnal project for yourself, because it’s nearly impossible to really know what you want \u0026amp;\u0026amp; separate it from what you want to want. It’s impossible to set “deadlines” if they’re not real, that is, imposed by an external authority.\nI had a personnal networking project at university. Since they had good equipments laying arround, i politely asked if i could use it for learning purposes, \u0026amp;\u0026amp; also to write a post about it later.\nBut i never published this post, because i couldn\u0026rsquo;t tell where the end of the project would be. It’s impossible to start something and, given enough time and input, not have it grow \u0026amp;\u0026amp; evolve into something else entirely. It’s impossible to avoid scope creep.\nHere is some images of the draft post. (you can click to zoom on them)\nMany of my personnal projects are out of my control because i told myself so many times that \u0026ldquo;it lacks of [\u0026hellip;], it\u0026rsquo;s fine, i\u0026rsquo;ll do it later\u0026rdquo;, or i learn something new because i dug further onto the subject so \u0026ldquo;what i done is incredibly wrong, i\u0026rsquo;ll start it over\u0026rdquo; : \u0026amp;\u0026amp; it never ends\nJe retiens que si je fais un projet perso, peu importe avec quoi || dans quel domaine : je dois d\u0026rsquo;abord me projeter sur ce que je dois avoir plutôt que ce que je veux avoir, vraiment. Sinon, ce que je veux qu\u0026rsquo;il soit ne cessera de changer parce que j\u0026rsquo;apprendrai, parce que je changerai d\u0026rsquo;idée - parce que je le fais pour moi. Je ne fixerai pas non plus de deadline vu que j\u0026rsquo;ai le temps. Je définis maintenant ce que je fais par rapport à ce que je veux avoir au bout, pas par rapport à ce que j\u0026rsquo;ai envie d\u0026rsquo;avoir.\nJe dépense une quantité folle de temps parce que je ne peux pas me fixer une limite de temps à ce que je veux : j\u0026rsquo;ajoute des choses au fur \u0026amp;\u0026amp; à mesure que le projet avance, car je le fais pour moi. En recherche, si on aborde un sujet, si on ne s\u0026rsquo;y met pas de limites, on fini par jamais finir de l\u0026rsquo;étudier.\nLes cours nous donne des délais, une limite de temps à ne pas dépasser pour un module. Quand on fait un projet perso, si on ne se fixe pas de limite, c\u0026rsquo;est pas possible de prévoir le temps qu\u0026rsquo;on va y mettre || de le délimiter si on ne sait pas ce qu\u0026rsquo;on voudra que le projet soit dans 3, 5 jours.\nI stopped to told myself that it will be done when it\u0026rsquo;s done, otherwise it will never be\n","date":"2023-12-23","externalUrl":null,"permalink":"/posts/work-thoughts/","section":"Posts","summary":"writing some thoughts,","title":"work thoughts","type":"posts"},{"content":"","date":"2023-10-22","externalUrl":null,"permalink":"/tags/cisco/","section":"Tags","summary":"","title":"Cisco","type":"tags"},{"content":" utilisation du protocole\nhsrp sur routeurs cisco introduction # dernier article de la série des explications sur le module r301, dédié au protocole hsrp\nson implémentation simple ne prend pas beaucoup de temps\nfonctionnement # hot standby router protocol\nprotocole de redondance de passerelle dans un réseau local\n%%{init: {'theme':'dark'}}%% graph TD subgraph 192.168.0.1 r1{R1\n192.168.0.2} r2{R2\n192.168.0.3} end sw1[SW1] pc1[PC1] pc2[PC2] r1 --- sw1 r2 --- sw1 sw1 --- pc1 \u0026 pc2 deux routeurs se partagent une adresse ip virtuelle, ici 192.168.0.1\nles machines du réseau local PC1 \u0026amp; PC2 utilisent l\u0026rsquo;adresse virtuelle comme passerelle par défaut\nhsrp définit un routeur comme actif R1 \u0026amp; l\u0026rsquo;autre comme passif R2\nles routeurs communiquent entre eux pour savoir qui redirige le traffic de l\u0026rsquo;ip virtuelle : si l\u0026rsquo;actif n\u0026rsquo;est plus présent, le deuxième routeur en \u0026ldquo;standby\u0026rdquo; prend le relai\nle routeur passif R2 prendra la redirection si il ne reçoit plus de message hsrp hello du routeur R1\nsi R1 renvoie des messages hello par la suite, il reprendra la redirection\nle routeur avec la priorité la plus haute sera l\u0026rsquo;actif, sera le premier routeur avec la priorité inférieure la plus haute celui qui reprendra, \u0026amp; en suivant\u0026hellip;\nles routeurs se partagent leur configuration, l\u0026rsquo;intervale de temps de synchronisation peut être défini, pareil pour les messages hello\nimplémentation # configuration du routeur actif R1, avec une priorité de 110\nenable configure terminal hostname R1 no ip domain-lookup interface fa0/0 ip address 192.168.0.2 255.255.255.0 standby 100 ip 192.168.0.1 standby 100 priority 110 standby 100 preempt no shutdown end 100 numéro groupe hsrp (applicable ensuite)\nstandby 100 ip 192.168.0.1 définition adresse ip virtuelle\nstandby 100 priority 110 numéro de priorité pour ce routeur\nstandby 100 preempt active préemption -\u0026gt; si nouveau routeur avec plus haute priorité arrive dans un groupe, il devient l\u0026rsquo;actif\nconfiguration du routeur passif R2, avec une priorité de 100\nenable configure terminal hostname R2 no ip domain-lookup interface fa0/0 ip address 192.168.0.3 255.255.255.0 standby 100 ip 192.168.0.1 standby 100 priority 100 standby 100 preempt no shutdown end le routeur R1 a une priorité de 110 \u0026amp; R2 de 100\nR1 -\u0026gt; actif, R2 -\u0026gt; passif\npour tester la configuration, après configuration réseau du PC1 ou PC2, ping -t 192.168.0.1 (ping à l\u0026rsquo;infini) depuis un pc\nsi lien coupé entre R1 \u0026amp; SW1 : après quelques timeout (5 secondes), les ping reprennent car R2 reprend la redirection\nc\u0026rsquo;est de la haute disponibilité (redondance avec un système de bascule et réplication de la configuration) resiliency != redundancy\nR2 prend le relai après environ 3 timeout car se laisse une marge d\u0026rsquo;erreur avant de s\u0026rsquo;attribuer l\u0026rsquo;ip virtuelle\nquand R1 revient, un timeout est présent le temps qu\u0026rsquo;il reprenne l\u0026rsquo;adresse virtuelle\n","date":"2023-10-22","externalUrl":null,"permalink":"/posts/cisco-hsrp/","section":"Posts","summary":"utilisation du protocole","title":"cisco hsrp","type":"posts"},{"content":"","date":"2023-10-22","externalUrl":null,"permalink":"/tags/french/","section":"Tags","summary":"","title":"French","type":"tags"},{"content":"","date":"2023-10-22","externalUrl":null,"permalink":"/series/r301/","section":"Series","summary":"","title":"R301","type":"series"},{"content":"","date":"2023-10-22","externalUrl":null,"permalink":"/series/","section":"Series","summary":"","title":"Series","type":"series"},{"content":" compréhension du protocole\nospf sur routeurs cisco introduction # dans mon avancée sur les explications du module r301, je m\u0026rsquo;attaque au routage dynamique avec ospf\nencore une fois, cette série a pour but de se familiariser aux principes des protocoles \u0026amp; aux commandes pour les tp\nce n\u0026rsquo;est pas une application avancée pour les lab, c\u0026rsquo;est un point de départ\nroutage dynamique # dans notre utilisation des routeurs cisco, nous étions conformés au routage statique\naprès avoir renseigné des adresses ip sur leurs interfaces, les routeurs créaient leur table de routage en conséquent, \u0026amp; nous ajoutions manuellement des routes pour les \u0026ldquo;réseaux cachés\u0026rdquo;\ncependant, pour gérer de grands réseaux (15, 20, 50+ routeurs\u0026hellip;) -\u0026gt; indiquer manuellement les routes sur chaque routeur peut vite devenir répétitif \u0026amp; fastidieux à la maintenance\nen opposition au routage statique, le routage dynamique permet aux routeurs de communiquer leur table de routage \u0026amp; de se créer dynamiquement leurs routes\nles algorithmes de recherche \u0026amp; de partage des routes sont définis par leur(s) protocole(s) de routage\nparmis les protocoles les plus connus: rip (choissant le nombre de routeur vers la destination le plus mince) \u0026amp; ospf (préférant l\u0026rsquo;état des liens entre les routeurs - leur débit, disponibilité\u0026hellip;)\nospf # open shortest path first\nest un protocole non affilié à cisco, regardant l\u0026rsquo;état des liens entre les routeurs, construisant son interprêtation du réseau\npour ceux qui l\u0026rsquo;ont vu en terminale, ospf est l\u0026rsquo;implémentation de l\u0026rsquo;algorithme de Dijkstra\ncelui-ci créer un coût se basant sur la bande passante (pour éviter la congestion) des liens \u0026amp;\u0026amp; sur leur disponibilité\nvoici un exemple d\u0026rsquo;utilisation de ospf\n%%{init: {'theme':'dark'}}%% graph LR r1{R1} r2{R2} r3{R3} r1 ---|100 Mits/s| r2 r1 ---|10 Mbits/s| r3 r2 ---|100 Mbits/s| r3 ici, pour aller de R1 à R3, ospf préfèrera passer par R2\nle coût d\u0026rsquo;utilisation de deux liens à 100 Mbits/s étant moins élevé que celui d\u0026rsquo;un lien à 10 Mbits/s\nle protocole rip aurait pris le lien entre R1 \u0026amp; R3, ayant le nombre de saut le plus court entre les deux\nune formule mathématique existe pour calculer les coûts, ce tableau résume les débits courants\nBande passanteCoût OSPF10 Gbits/s11 Gbits/s1100 Mbits/s110 Mbits/s101544 Kbps (série)64 ospf séctarise par zone qu\u0026rsquo;il appelle area\nun ensemble de routeurs font parti d\u0026rsquo;une area, deux areas pouvant s\u0026rsquo;interconnecter pour échanger leurs routes\nles routeurs avec ospf s\u0026rsquo;envoient des messages hello pour vérifier leurs configurations\nces messages passent par différentes STATES, full signifiant que les deux communiquants connaissent les mêmes réseaux - qu\u0026rsquo;ils ont bien appris de l\u0026rsquo;autre\nconfiguration # avant de commencer le routage dynamique, les adresses ip doivent être présentes sur les interfaces\nsuite à cela, la configuration de base de ospf peut commencer\nrouter ospf 1 numéro 1 pour indiquer le numéro de l\u0026rsquo;area/de la configuration\npour être identifié sur le réseau ospf, le routeur doit possèder un id\nsans configuration, cet id prendra l\u0026rsquo;adrese ip de l\u0026rsquo;interface la plus haute configurée (loopback puis interfaces physiques)\ncet id peut être changé en une commande, plutôt que de configurer une interface\nrouter-id 1.1.1.1 c\u0026rsquo;est juste une ip pour reconnaitre les routeurs, ici pour dire le routeur 1 par exemple (ils font comme ceci dans les lab)\nsinon\ninterface loopback 0 ip address 1.1.1.1 255.255.255.255 pour annoncer un réseau (ou une route\u0026hellip;), sera indiquée l\u0026rsquo;adresse ip du réseau\navec son masque mais inversé (wildcard)\ne.g. 255.255.255.0 -\u0026gt; 0.0.0.255\nsera aussi précisée la zone à laquelle appartient la route\nexemple d\u0026rsquo;annonce d\u0026rsquo;une route pour le réseau 192.168.0.0/24 pour la zone 1 sur le réseau ospf\nnetwork 192.168.0.0 0.0.0.255 area 1 sous la forme network \u0026lt;ip réseau\u0026gt; \u0026lt;wildcard\u0026gt; area \u0026lt;numéro zone\u0026gt;\narea 1 un chiffre ou un nombre pour identifier la zone\nla configuration peut aussi se faire avec l\u0026rsquo;ip de l\u0026rsquo;interface (network \u0026lt;ip interface\u0026gt; \u0026lt;wildcard\u0026gt; area \u0026lt;numéro zone\u0026gt;)\nvérifications # vérifier ses voisins ospf\nshow ip ospf neighbor voir si des routes sont crées par ospf\nshow ip route toutes les routes commençant par un O sont apprises par ospf -\u0026gt; show ip route | begin O\nregarder les états des messages HELLO\nshow ip ospf interface pour une interface spécifique\nshow ip ospf interface se0/1/0 voir si ospf est actif comme protocole de routage\nshow ip protocols deux moyens de changer le coût d\u0026rsquo;une interface\ninterface se0/1/0 bandwith 64 interface se0/1/0 ip ospf cost 10 changer les intervales de messages HELLO ou DEAD\ninterface se0/1/1 ip ospf hello-interval 5 ip ospf dead-interval 20 ","date":"2023-10-20","externalUrl":null,"permalink":"/posts/cisco-ospf/","section":"Posts","summary":"compréhension du protocole","title":"cisco ospf","type":"posts"},{"content":" prise en main du routage\ninter-vlan sur équipements cisco introduction # je crée finalement une série d\u0026rsquo;articles dédiés à r301, le module abordant du cisco cli évalué en pratique\ncet article est dédié à la compréhension \u0026amp; à l\u0026rsquo;étude des principes liés au routage inter-vlan, pas à de l\u0026rsquo;exploration technique ou une utilisation avancée\nj\u0026rsquo;expose uniquement les bases du routage inter-vlan, libre à vous de chercher plus loin\nsi vous avez compris cet article, les tp devraient être sympa à faire\nrappels vlan # les vlan servent à faire de la ségmentation réseau\nles machines d\u0026rsquo;un vlan ne pourront communiquer qu\u0026rsquo;avec les autres machines du même vlan (ségmentation)\nl\u0026rsquo;application des vlans se fait généralement sur un switch\nles ports d\u0026rsquo;un switch sont associés à un (ou plusieurs) vlans, les machines derrières ces ports sont par conséquent affectées à ces vlans sans qu\u0026rsquo;elles ne le sachent\nde ce fait, les machines du vlan X auront accès uniquement aux autres machines du vlan X, si tous les liens entre les deux autorisent le passage de ce vlan\nside note: tous les ports d\u0026rsquo;un switchs ont un vlan par défaut \u0026amp; natif : le vlan 1, donc tout le monde se voit partout\nen français on appelerait ça le \u0026ldquo;taggage de paquets IP\u0026rdquo;, chaque trâme étant taguée par un vlan par le protocole 801.1q, ou isl\nprincipes d\u0026rsquo;inter-vlan # les vlans ségmentarisent les réseaux sur la couche 2 du modèle OSI\nil n\u0026rsquo;est pas possible de les contourner en remontant les couches, ni en les descendant (aller sur le support\u0026hellip;)\ncependant, il est parfois nécessaire de faire communiquer des machines appartenant à des vlans différents\nune machine devrait donc se charger de faire passer les trâmes d\u0026rsquo;un vlan pour un autre vlan\nle remède à tout ça serait un routeur, qui transfère les trames d\u0026rsquo;un vlan à un autre, comme d\u0026rsquo;un réseau à un autre\ncela existe sur beaucoup de routeurs (pas que cisco)\nleur spécificité étant qu\u0026rsquo;ils font du routage entre les vlan : du routage inter-vlan\nnotions annexes # cette notion sera abordée pour la suite\nun lien peut transporter plusieurs vlans, mais ces vlans ne se verront pas\nil faut que les ports aux extrémités du lien soient configurés de la même manière (sur deux switchs par exemple)\npour faire passer plusieurs vlans sur un seul lien, il sera monté en mode trunk\nméthodes d\u0026rsquo;inter-vlans # un routeur peut faire du routage inter-vlan de la même manière qu\u0026rsquo;il le fait pour des réseaux physiques\nun exemple ici\n%%{init: {'theme':'dark'}}%% graph TD r1{R1} sw1[SW1] sw2[SW2] pc1[PC1] pc2[PC2] r1 ---|vlan 10| sw1 r1 ---|vlan 20| sw2 sw1 ---|vlan 10| pc1 sw2 ---|vlan 20| pc2 cependant, selon les réseaux, un bien plus grand nombre de vlan peut être amené à être routé (30, 50+ \u0026hellip;)\nl\u0026rsquo;idée de garder un lien par vlan, comme on le ferait pour un réseau, devient alors insensée\nl\u0026rsquo;utilisation des ports en mode trunk est alors conseillé pour transporter plusieurs vlan sur un seul lien\nle routeur comprenant l\u0026rsquo;arrivée des trâmes taguées\nle routage devenant alors on stick\n%%{init: {'theme':'dark'}}%% graph TD r1{R1} sw1[SW1] pc1[PC1] pc2[PC2] r1 ---|trunk\nvlan 10, 20\n| sw1 sw1 ---|vlan 10| pc1 sw1 ---|vlan 20| pc2 routage simple # comme dit méthodes d\u0026rsquo;inter-vlan, le routage peut se faire en utilisant des liens physiques\ncette méthode n\u0026rsquo;est pas utilisée car serait beaucoup trop couteuse \u0026amp; inutile (pour 48 vlan, acheter un routeur physique de 48 ports ça ne se fait pas\u0026hellip;)\nje l\u0026rsquo;expose tout de même ici car demandé en tp\nles notions de routage restent les mêmes, les vlans ayant des adresses réseaux différentes -\u0026gt; c\u0026rsquo;est comme des réseaux physiques\nsi l\u0026rsquo;on se base sur la topologie suivante\ntélécharger le fichier packet tracer vierge voici les commandes de configuration des équipements\nj\u0026rsquo;omets d\u0026rsquo;expliquer les commandes: elles devraient être transparentes -\u0026gt; ce sont les mêmes que pour du routage simple\nconfiguration du switch SW1\nenable configure terminal hotsname SW1 no ip domain-lookup int g0/1 switchport access vlan 10 int g1/1 switchport access vlan 20 int g2/1 switchport access vlan 10 int g3/1 switchport access vlan 20 end les ports d\u0026rsquo;un switch sont UP par défaut, pas besoin de la commande no shutdown\npas besoin de la commande switchport mode access, les ports le sont par défaut\npas besoin de déclarer les vlan, vlan 10 par exemple, s\u0026rsquo;ils ne sont pas déjà crées le switch le fera à la volée\nconfiguration du routeur R1\nenable configure terminal hotsname R1 no ip domain-lookup int g0/0 ip address 192.168.1.1 255.255.255.0 no shut int g1/0 ip address 192.168.2.1 255.255.255.0 no shut end après l\u0026rsquo;attribution d\u0026rsquo;une adresse ip à PC1 \u0026amp; PC2 \u0026amp; renseignement de leur passerelle -\u0026gt; ils pourront communiquer\nattendez bien quelques secondes que le ping se terminent\u0026hellip;\nroutage on stick # le routage inter-vlan on stick possède les mêmes propritétés que le routage inter-vlan simple\nl\u0026rsquo;unique exception étant l\u0026rsquo;utilisation d\u0026rsquo;un lien trunk pour le passage des vlans du switch au routeur\ncela implique au routeur de connaitre les vlans transmis sur ce lien -\u0026gt; pour se configurer une adresse ip sur chaque vlan \u0026amp; leur servir de passerelle\npour cela, le routeur va découper son interface en sous-interfaces pour chaque vlan demandé\nces sous-interfaces seront les passerelles des machines pour leur réseau local (définies par le vlan sur lequel elles sont)\nje considèrerai l\u0026rsquo;infrastructure suivante\ntélécharger le fichier packet tracer vierge configuration R1\nenable configure terminal hostname R1 no ip domain-lookup int g0/0 no shutdown int g0/0.10 encapsulation dot1Q 10 ip address 192.168.1.1 255.255.255.0 no shut int g0/0.20 encapsulation dot1Q 20 ip address 192.168.2.1 255.255.255.0 no shut end int g0/0.10 créer la sous-interface 10 sur le port GigabitEthernet0/0\nencapsulation dot1Q 10 utilisera le vlan 10 sur cette interface\nNote Pour que les sous-interfaces fonctionnent, il faut que l\u0026rsquo;interface sur laquelle elles sont déclarées soit en no shutdown (pour ne pas que vous panniquiez aucontrôle\u0026hellip;) configuration SW1\nenable configure terminal hostname SW1 no ip domain-lookup int g0/1 switchport mode trunk int g1/1 switchport access vlan 10 int g2/1 switchport access vlan 20 end pas besoin de créer un vlan avec la commande vlan 10 par exemple, si inexistant -\u0026gt; il va le créer\npas besoin switchport trunk allowed vlan 10,20 car ne fait pas de restriction par défaut, accepte tous les vlans\npas besoin switchport trunk native vlan 1 non plus\ncommandes utiles pour débogger\nshow running-config show ip route show ip interface brief ","date":"2023-10-18","externalUrl":null,"permalink":"/posts/cisco-inter-vlan/","section":"Posts","summary":"prise en main du routage","title":"inter-vlan cisco","type":"posts"},{"content":" authentification par\nclés ssh sur équipements cisco introduction # les équipements cisco (switchs, routeurs, asa\u0026hellip;) tournent sur une distribution gnu/linux cisco ios\nsera couvert la configuration \u0026amp; la connexion en ssh à ces équipements via une paire de clés ssh\ngénération des clés # sera utilisée une vm ubuntu pour la génération des clés ssh\ncisco ios supporte uniquement l\u0026rsquo;algorithme de chiffrement rsa\nla taille des clés est à votre convenance (1024, 2048, 4096\u0026hellip; bits)\nje recommande 1024 bits, les processeurs des équipements cisco à l\u0026rsquo;iut sont vieux donc prennent du temps pour des tailles de clés plus élevées\u0026hellip;\ngénération d\u0026rsquo;une paire de clés ssh dans ~/.ssh/ suivant l\u0026rsquo;algorithme de chiffrement rsa avec une longueur 1024 bits, sans passphrase\nNote si vous changez la longueur de la clé, retenez la pour plus tard ssh-keygen -t rsa -b 1024 -N \u0026#34;\u0026#34; -f \u0026#34;$HOME/.ssh/cisco-ssh\u0026#34; -t rsa choix de l\u0026rsquo;algorithme de chiffrement\n-b 1024 précision de la longueur de la clé\n-c \u0026quot;~/.ssh/cisco-ssh.key\u0026quot; définition de leur emplacement\n-N \u0026quot;\u0026quot; indication passphrasse (aucune)\nclé privée ~/.ssh/cisco-ssh, clé publique ~/.ssh/cisco-ssh.pub\nla taille minimum d\u0026rsquo;une clé rsa avec ssh en version 2 est de 768 bits, j\u0026rsquo;ai préféré prendre 1024 car plus courant\nla clé publique devra être renseignée sur l\u0026rsquo;équipement cisco\npour afficher son contenu\ncat ~/.ssh/cisco-ssh.pub exemple de sortie de la commande\n1ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAAAgQDXRp1IYBPwCUtXXwAlY3ewRY6lb9zO+LQ80Ynb1hLFq58F+3ui+MoyRYrD4uIK8Z3B91nQf0zhrmYGKVQHpdgvoWclp8E0QUcwAuWdZLl3zTt5nz97+h10yFg9eTnAYyPOZpaC5J/Obw34yM1pJAWPPrFo+no6KslsFNgFjOlvlQ== xeylou@null le contenu effectif de la clé serait sans le ssh-rsa au début \u0026amp; le commentaire en fin (ici xeylou@null)\nla clé peut être renseignée avec ces informations quand même\ncependant, elle occupe une seule grande ligne\nor, cisco ios supporte maximum 254 caractères par ligne de commande\nla clé sera renseignée par paquets équivalents de 72 octets\nfold -b -w 72 ~/.ssh/cisco-ssh.pub exemple de sortie de la commande\n1 2 3 4 ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAAAgQDXRp1IYBPwCUtXXwAlY3ewRY6lb9zO+LQ8 0Ynb1hLFq58F+3ui+MoyRYrD4uIK8Z3B91nQf0zhrmYGKVQHpdgvoWclp8E0QUcwAuWdZLl3 zTt5nz97+h10yFg9eTnAYyPOZpaC5J/Obw34yM1pJAWPPrFo+no6KslsFNgFjOlvlQ== xey lou@null ce sera le contenu à coller dans la configuration de l\u0026rsquo;équipement\nNote pour le copier depuis un terminal, selectionnez puis faites CTRL + ↑ + C configuration sur routeur # pour un routeur cisco 2901 configuré comme suivant\nenable configure terminal hostname GASPARD no ip domain-lookup renseignement d\u0026rsquo;un domaine contingeant à la création de l\u0026rsquo;environnement ssh (pas important)\ngénération d\u0026rsquo;une paire de clés rsa 1024 bits pour initier l\u0026rsquo;environnement ssh\nGénérez une paire de clés de même longueur que celles générées sur la vm ip domain-name rzo.local crypto key generate rsa modulus 1024 création d\u0026rsquo;un utilisateur pour la connexion\nutilisation de l\u0026rsquo;algorithme de chiffrement sha256 au lieu de md5 par défaut (256 bits contre 128)\nusername xeylou privilege 15 algorithm-type sha256 secret motdepasse privilege 15 mêmes permissions que enable\nalgorithm-type sha256 choix méthode de chiffrement du mot de passe\nsecret motdepasse définition d\u0026rsquo;un mot de passe (optionnel)\nles lignes virtuelles sont des supports pour accéder à l\u0026rsquo;interface de commande cisco à distance\nles anciennes versions de cisco ios en ont 5 (0-4) sinon 16 (0-15), \u0026amp;\u0026amp; encore ça peut varier\u0026hellip;\nconfiguration des lignes virtuelles pour y accéder uniquement via une connexion ssh enregistrée sur la base d\u0026rsquo;utilisateurs locale\nline vty 0 15 transport input ssh login local passage de ssh version 1 à 2 (désactivation de la version 1)\nip ssh version 2 importation de la clé publique à l\u0026rsquo;utilisateur xeylou\nip ssh pubkey-chain username xeylou key-string coller la clé publique découpée sur la vm ici\nindication de la fin de la clé\nexit désactivation de tous les types d\u0026rsquo;authentification sauf par clé ssh (publickey)\nces commandes peuvent ne pas être supportées par la version de cisco ios utilisée, je les donne quand même\nno ip ssh server authenticate user password no ip ssh server authenticate user keyboard attribution d\u0026rsquo;une adresse ip à une des interfaces du routeur\nint g0/0 ip address 192.168.0.1 255.255.255.0 no shut configuration sur switch # la configuration ssh est identique pour un switch\nenable configure terminal hostname SW7 no ip domain-lookup ip domain-name rzo.lan crypto key generate rsa modulus 4096 username xeylou privilege 15 algorithm-type sha256 secret motdepasse line vty 0 15 login local transport input ssh ip ssh version 2 ip ssh pubkey-chain username xeylou key-string renseignement de la clé publique ici\nexit no ip ssh server authenticate user password no ip ssh server authenticate user keyboard configuration de l\u0026rsquo;interface d\u0026rsquo;accès qui sera un vlan\nun vlan dédié serait préférable, mais bon!\nint vlan 1 ip add 192.168.0.2 255.255.255.0 no shut connexion ssh # configuration des commandes ssh gaspard \u0026amp; ssh sw7 pour se connecter aux équipements depuis la vm\nsur l\u0026rsquo;hôte qui accédera aux équipements (la vm)\nnano ~/.ssh/config cisco ios utilise des protocoles obsolètes que openssh refuse d\u0026rsquo;utiliser par défaut\nrenseignement de ceux-ci dans la configuration des alias\nrenseignement pour le routeur\n1 2 3 4 5 6 7 Host gaspard hostname = 192.168.0.1 user = xeylou KexAlgorithms = diffie-hellman-group-exchange-sha1 HostKeyAlgorithms = ssh-rsa PubKeyAcceptedAlgorithms = ssh-rsa IdentityFile \u0026#34;~/.ssh/cisco-ssh\u0026#34; KexAlgorithms changement d\u0026rsquo;algorithme d\u0026rsquo;échange de clé\nHostKeyAlgorithms chiffrement proposé par la vm ubuntu\nPubKeyAcceptedAlgorithms pareil par l\u0026rsquo;équipement\nune manipulation supplémentaire est à faire pour le switch\nles ciphers définissent les algorithmes utilisés pour sécuriser la connexion ssh (ne pas transmettre en clair dès le départ)\nrajout d\u0026rsquo;une ligne pour définir un cipher supporté par les switchs\n9Host sw7 10 hostname = 192.168.0.2 11 user = xeylou 12 KexAlgorithms = diffie-hellman-group-exchange-sha1 13 HostKeyAlgorithms = ssh-rsa 14 PubKeyAcceptedAlgorithms = ssh-rsa 15 IdentityFile \u0026#34;~/.ssh/cisco-ssh\u0026#34; 16 Ciphers aes256-cbc connexion en ssh depuis la vm ubuntu\nssh gaspard ssh sw7 pensez à être sur le même réseau que les équipements\nà cette étape, vous devriez normalement pouvoir vous connecter au routeur \u0026amp; au switch sans avoir à renseigner de mot de passe\nune fois une connexion ssh active initiée, vous êtes au même niveau qu\u0026rsquo;un enable sur un port console (tous les droits)\nje suis toujours là si des choses se sont mal passées ou que tout est vraiment nul\nsupplément # vérification concordance des clés\ngénération d\u0026rsquo;une empreinte (fingerprint) des clés publiques des deux côtés (équipements \u0026amp; machine cliente) savoir si elles sont jumelles\nsur les équipements\nshow running-config | begin pubkey comparable au hash sur la vm ubuntu\nssh-keygen -l -f $HOME/.ssh/cisco-ssh.key.pub définition d\u0026rsquo;une acl pour autoriser uniquement les adresses ip locales à se connecter en ssh\nenable configure terminal ip access-list standard SSH_ACL permit 192.168.0.0 0.0.0.255 line vty 0 15 access-class SHH_ACL in ajout d\u0026rsquo;un timeout au bout de 10 minutes d\u0026rsquo;inactivité sinon infini\nexec timeout 10 0 définition de maximum 3 tentatives de connexion ralentissement de bruteforce\nip ssh authentication-retries 3 service tcp-keepalives-in service tcp-keepalives-out activation de scp pour transfert de fichiers via ssh\nip scp server enable ","date":"2023-10-03","externalUrl":null,"permalink":"/posts/ssh-cisco-ios/","section":"Posts","summary":"authentification par","title":"ssh cisco ios","type":"posts"},{"content":"","date":"2023-10-03","externalUrl":null,"permalink":"/tags/workshop/","section":"Tags","summary":"","title":"Workshop","type":"tags"},{"content":"","date":"2023-09-30","externalUrl":null,"permalink":"/tags/dns/","section":"Tags","summary":"","title":"Dns","type":"tags"},{"content":"","date":"2023-09-30","externalUrl":null,"permalink":"/tags/mail/","section":"Tags","summary":"","title":"Mail","type":"tags"},{"content":" installation d\u0026rsquo;un serveur mail mx postfix\navec dovecot \u0026amp; utilisation avec thunderbird introduction # je continue l\u0026rsquo;avancée des workshops avec un serveur mail postfix avec dovecot, pour l\u0026rsquo;envoi \u0026amp; la réception de mails\nil pourra être utilisé avec utilisateurs gnu/linux ou virtuels\ntopologie utilisée\n%%{init: {'theme':'dark'}}%% graph TD subgraph 192.168.122.0/24 postfix[r303-deb12-postfix\n192.168.122.10] bind9[r303-deb12-bind9\n192.168.122.11] thunderbird[r303-deb12-client\n192.168.122.12] pstf(Service Postfix) dovecot(Service Dovecot) bind(Service Bind9) clients(Mozilla Thunderbird) gw{NAT\n192.168.122.1} end wan{WAN} wan --- gw gw --- postfix \u0026 bind9 gw --- thunderbird postfix -.- pstf \u0026 dovecot bind9 -.- bind thunderbird -.- clients vm postfix # modification nom d\u0026rsquo;hôte\nhostnamectl set-hostname r303-deb12-postfix \u0026amp;\u0026amp; logout attribution adresse ip statique\nnano /etc/network/interfaces 4 5 6 7 8 9 10 11 12 13 14 source /etc/network/interfaces.d/* # The loopback network interface auto lo iface lo inet loopback # The primary network interface allow-hotplug enp1s0 iface enp1s0 inet static address 192.168.122.10/24 gateway 192.168.122.1 systemctl restart networking installation paquet postfix \u0026amp; mailutils pour envoi/réception de mails entre utilisateurs\napt install -y postfix mailutils Internet Site -\u0026gt; rzo.lan\npour que postfix propose de prendre un nom de domaine, qui sera finalement utilisé pour les mails\nsi installation sans accroc : service postfix actif\nsystemctl status postfix fichier de configuration global postfix /etc/postfix/main.cf\ncommente tout ce qui touche au tls car pas utilisé ici\najout d\u0026rsquo;informations pour l\u0026rsquo;utilisation du service\nnano /etc/postfix/main.cf 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 # TLS parameters # smtpd_tls_cert_file=/etc/ssl/certs/ssl-cert-snakeoil.pem # smtpd_tls_key_file=/etc/ssl/private/ssl-cert-snakeoil.key # smtpd_tls_security_level=may # smtp_tls_CApath=/etc/ssl/certs # smtp_tls_security_level=may # smtp_tls_session_cache_database = btree:${data_directory}/smtp_scache mydomain = rzo.lan # smtpd_relay_restrictions = permit_mynetworks permit_sasl_authenticated defer_unauth_destination myhostname = r303-deb12-postfix.rzo.lan alias_maps = hash:/etc/aliases alias_database = hash:/etc/aliases myorigin = /etc/mailname mydestination = $mydomain, $myhostname, localhost.$mydomain, localhost # relayhost = mynetworks = 127.0.0.0/8 192.168.122.0/24 home_mailbox = Maildir/ mailbox_size_limit = 51200000 recipient_delimiter = + inet_interfaces = all inet_protocols = ipv4 alias_maps table des noms \u0026amp; des adresses de mydestination\nalias_database table des noms d\u0026rsquo;usages de alias_maps\nmyorigin pas de nom de domaine -\u0026gt; ajoute celui dans fichier\nmydestination domaines acceptés d\u0026rsquo;échange\nrecipient_delimiter truc@$mydomain \u0026amp; truc+random@$mydomain == les mêmes (pourriel)\nvérification syntaxique après édition\npostfix check redémarrage du service pour appliquer les modifications\nsystemctl restart postfix création de deux users gnu/linux\nNote mot de passe contingeant à l\u0026rsquo;authentification\u0026hellip; adduser --gecos \u0026#34;\u0026#34; user1 \u0026amp;\u0026amp; adduser --gecos \u0026#34;\u0026#34; user2 connexion à l\u0026rsquo;un des deux users pour test d\u0026rsquo;envoi\nsu user1 mail user2 Cc:\nSubject: test envoi user2\ncontenu du mail\nenvoi avec retour à la ligne puis CTRL + D\nconnexion sur l\u0026rsquo;utilisateur récepteur\nsu user2 vérification de la réception du mail\nls ~/Maildir/new/ | wc -l 1 si nouveau mail car fichier dans ~/Maildir/new/\ndossier ~/Maildir défini dans /etc/postfix/main.cf\ndovecot # serveur imap \u0026amp; pop3\ninstallation du daemon imap de dovecot\napt install -y dovecot-imapd autres paquets dans la suite dovecot-*, e.g. dovecot-ldap pour support ldap\nfichiers de configuration de dovecot dans /etc/dovecot/conf.d/\nmodification des méthodes d\u0026rsquo;authentification\nnano /etc/dovecot/conf.d/10-auth.conf précision de tout laisser passer en clair\n5 6 7 8 9 10 # Disable LOGIN command and all other plaintext authentications unless # SSL/TLS is used (LOGINDISABLED capability). Note that if the remote IP # matches the local IP (ie. you\u0026#39;re connecting from the same computer), the # connection is considered secure and plaintext authentication is allowed. # See also ssl=required setting. disable_plaintext_auth = no définition des méchanismes d\u0026rsquo;authentification (login obsolète mais toujours utilisé)\n96 97 98 99 100 # Space separated list of wanted authentication mechanisms: # plain login digest-md5 cram-md5 ntlm rpa apop anonymous gssapi otp # gss-spnego # NOTE: See also disable_plaintext_auth setting. auth_mechanisms = plain login modification de l\u0026rsquo;emplacement de destination des mails\nnano /etc/dovecot/conf.d/10-mail.conf 22 23 24 25 26 27 28 29 30 # See doc/wiki/Variables.txt for full list. Some examples: # # mail_location = maildir:~/Maildir # mail_location = mbox:~/mail:INBOX=/var/mail/%u # mail_location = mbox:/var/mail/%d/%1n/%n:INDEX=/var/indexes/%d/%1n/%n # # \u0026lt;doc/wiki/MailLocation.txt\u0026gt; # mail_location = maildir:~/Maildir modification de la gestion des logs - a été utile\nnano /etc/dovecot/conf.d/10-logging.conf 5 6 7 8 9 10 11 12 13 14 15 16 17 # Log file to use for error messages. \u0026#34;syslog\u0026#34; logs to syslog, # /dev/stderr logs to stderr. log_path = /var/log/dovecot.log # Log file to use for informational messages. Defaults to log_path. #info_log_path = # Log file to use for debug messages. Defaults to info_log_path. #debug_log_path = # Syslog facility to use if you\u0026#39;re logging to syslog. Usually if you don\u0026#39;t # want to use \u0026#34;mail\u0026#34;, you\u0026#39;ll use local0..local7. Also other standard # facilities are supported. syslog_facility = mail 39 40 # Log unsuccessful authentication attempts and the reasons why they failed. auth_verbose = yes 50 51 52 # Even more verbose logging for debugging purposes. Shows for example SQL # queries. auth_debug = yes application des modifications\nsystemctl restart dovecot vérification du fonctionnement\ntelnet -l user1 localhost 143 a login user2 user2\noù user2 l\u0026rsquo;utilisateur et user2 son mot de passe\nutilisateurs virtuels # création user vmail avec /opt/messagerie comme home directory\ncréation groupe vmail avec group id de 5000\ngroupadd -g 5000 vmail création du user\nuseradd -g vmail -u 5000 vmail -d /opt/messagerie -m -g son groupe\n-u 5000 user id de 5000\n-d /opt/messagerie son répertoire utilisateur/home ~\n-m créer son ~ si inexistant\nindication à postfix de vmail \u0026amp; du repertoire /opt/messagerie pour la gestion des boites aux lettres\nnano /etc/postfix/main.cf 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 # TLS parameters # smtpd_tls_cert_file=/etc/ssl/certs/ssl-cert-snakeoil.pem # smtpd_tls_key_file=/etc/ssl/private/ssl-cert-snakeoil.key # smtpd_tls_security_level=may # smtp_tls_CApath=/etc/ssl/certs # smtp_tls_security_level=may # smtp_tls_session_cache_database = btree:${data_directory}/smtp_scache mydomain = rzo.lan # smtpd_relay_restrictions = permit_mynetworks permit_sasl_authenticated defer_unauth_destination myhostname = r303-deb12-postfix.rzo.lan alias_maps = hash:/etc/aliases alias_database = hash:/etc/aliases myorigin = /etc/mailname mydestination = $mydomain, $myhostname, localhost.$mydomain, localhost default_transport = dovecot mail_spool_directory = /opt/messagerie/ virtual_mailbox_base = /opt/messagerie/ virtual_mailbox_domains = hash:/etc/postfix/vdomain virtual_mailbox_maps = hash:/etc/postfix/vmail virtual_alias_maps = hash:/etc/postfix/valias virtual_uid_maps = static:5000 virtual_gid_maps = static:5000 # relayhost = mynetworks = 127.0.0.0/8 192.168.122.0/24 home_mailbox = Maildir/ mailbox_size_limit = 51200000 recipient_delimiter = + inet_interfaces = all inet_protocols = ipv4 default_transport protocole/serveur d\u0026rsquo;envoi, par défaut smtp\nmail_spool_directory dossier de stockage des mails\nvirtual_mailbox_domains liste domaines où postfix destinataire\nvirtual_mailbox_maps adresses valides de virtual_mailbox_domains\nvirtual_uid_maps user id pour écrire les mails\nvirtual_uid_maps pareil que virtual_uid_maps pour group id\ndéfinition du domaine virtuel\nnano /etc/postfix/vdomain Note pas le droit d\u0026rsquo;être le même que celui dans postfix 1 rzo.private # création de messageries virtuelles accordément à virtual_mailbox_maps\nnano /etc/postfix/vmail 1 2 3 xeylou@rzo.private rzo.private/xeylou/ testing@rzo.private rzo.private/testing/ admin@rzo.private rzo.private/admin/ définition des alias virtuels pour ces utilisateurs vu virtual_alias_maps\nnano /etc/postfix/valias 1 2 root: admin@rzo.private xeylou: xeylou@rzo.private création d\u0026rsquo;un daemon postfix pour dovecot/vmail\nnano /etc/postfix/master.cf 138 139 dovecot unix - n n - - pipe flags=DRhu user=vmail:vmail argv=/usr/lib/dovecot/deliver -f ${sender} -d ${recipient} prise en compte des 3 fichiers modifiés\npostmap /etc/postfix/vdomain postmap /etc/postfix/vmail postalias /etc/postfix/valias postfix check modification dovecot # utilisation des comptes virtuels avec authentification correcte\nmodification de la méthode d\u0026rsquo;accès\nnano /etc/dovecot/conf.d/10-auth.conf 5 6 7 8 9 10 # Disable LOGIN command and all other plaintext authentications unless # SSL/TLS is used (LOGINDISABLED capability). Note that if the remote IP # matches the local IP (ie. you\u0026#39;re connecting from the same computer), the # connection is considered secure and plaintext authentication is allowed. # See also ssl=required setting. disable_plaintext_auth = yes ajout d\u0026rsquo;une méthode d\u0026rsquo;authentification sécurisée\n96 97 98 99 100 # Space separated list of wanted authentication mechanisms: # plain login digest-md5 cram-md5 ntlm rpa apop anonymous gssapi otp # gss-spnego # NOTE: See also disable_plaintext_auth setting. auth_mechanisms = cram-md5 plain login ajout du fichier auth-static.conf.ext dans la configuration\n122 123 124 125 126 127 #!include auth-system.conf.ext #!include auth-sql.conf.ext #!include auth-ldap.conf.ext #!include auth-passwdfile.conf.ext #!include auth-checkpassword.conf.ext !include auth-static.conf.ext définition de l\u0026rsquo;emplacement de la liste des utilisateurs virtuels + des mots de passe\nnano /etc/dovecot/conf.d/auth-static.conf.ext 16 17 18 19 20 21 22 23 24 25 26 27 28 passdb { # driver = static # args = password=test driver = passwd-file args = username_format=%u /etc/dovecot/dovecot.users } userdb { # driver = static # args = uid=vmail gid=vmail home=/home/%u driver = static args = uid=vmail gid=vmail home=/opt/messagerie/%d/%n/ allow_all_users=yes } informations user vmail pour récupération mails\nnano /etc/dovecot/conf.d/10-mail.conf 105 106 107 108 109 110 111 112 113 114 # System user and group used to access mails. If you use multiple, userdb # can override these by returning uid or gid fields. You can use either numbers # or names. \u0026lt;doc/wiki/UserIds.txt\u0026gt; mail_uid = 5000 mail_gid = 5000 # Group to enable temporarily for privileged operations. Currently this is # used only with INBOX when either its initial creation or dotlocking fails. # Typically this is set to \u0026#34;mail\u0026#34; to give access to /var/mail. mail_privileged_group = vmail définition des autorisations pour lister utilisateurs\nnano /etc/dovecot/conf.d/10-master.conf 100 101 102 103 104 105 106 107 108 109 110 unix_listener auth-userdb { #mode = 0666 user = vmail group = vmail } unix_listener /var/spool/postfix/private/auth { mode = 0666 user = postfix group = postfix } définition du hash des mots de passe des utilisateurs virtuels (vusers)\ndoveadm pw -s CRAM-MD5 Enter new password:\nRetype new password:\n{CRAM-MD5}e02d374fde0dc75a17a557039a3a5338c7743304777dccd376f332bee68d2cf6\nle coller dans /etc/dovecot/dovecot.users défini depuis /etc/dovecot/conf.d/auth-static.conf.ext\ndéfinition des mots de passe des vusers\nnano /etc/dovecot/dovecot.users 1 2 3 xeylou@rzo.private:{CRAM-MD5}e02d374fde0dc75a17a557039a3a5338c7743304777dccd376f332bee68d2cf6 testing@rzo.private:{CRAM-MD5}e02d374fde0dc75a17a557039a3a5338c7743304777dccd376f332bee68d2cf6 admin@rzo.private:{CRAM-MD5}e02d374fde0dc75a17a557039a3a5338c7743304777dccd376f332bee68d2cf6 les 3 utilisateurs ont le même mot de passe\nredémarrage des deux services\nsystemctl restart postfix systemctl restart dovecot vérification de leur fonctionnement\nsystemctl status postfix systemctl status dovecot pour débogger\njournalctl -xfe un des problèmes que j\u0026rsquo;ai eu\nOct 02 09:01:33 r303-deb12-postfix postfix/pipe[2905]: 940265FD8B: to=xeylou@rzo.private, relay=dovecot, delay=0.04, delays=0.02/0/0/0.02, dsn=4.3.0, status=deferred (temporary failure. Command output: lda(xeylou@rzo.private): Error: net_connect_unix(/run/dovecot/stats-writer) failed: Permission denied Can\u0026rsquo;t open log file /var/log/dovecot.log: Permission denied )\ncorrectif\nchown vmail:vmail /var/log/dovecot.log vm bind9 # installation du paquet bind9 + dépendances\napt install -y dbus bind9* dnsutils modification zones dns dans etc/bind/named.conf.local\nnano /etc/bind/named.conf.local 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 // // Do any local configuration here // // Consider adding the 1918 zones here, if they are not used in your // organization //include \u0026#34;/etc/bind/zones.rfc1918\u0026#34;; zone \u0026#34;rzo.lan\u0026#34; IN { type master; file \u0026#34;/etc/bind/rzo.lan\u0026#34;; }; zone \u0026#34;rzo.private\u0026#34; IN { type master; file \u0026#34;/etc/bind/rzo.private\u0026#34;; }; zone \u0026#34;122.168.192.in-addr.arpa\u0026#34; { type master; file \u0026#34;/etc/bind/rzo.lan.inverse\u0026#34;; }; vérification syntaxique\nnamed-checkconf /etc/bind/named.conf.local édition de celles-ci\nnano /etc/bind/rzo.lan 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 $TTL 86400 $ORIGIN rzo.lan. @ IN SOA ns.rzo.lan. admin.rzo.lan. ( 2023100101 ; serial 21600 ; refresh 10800 ; retry 43200 ; expire 10800 ) ; minimum @ IN NS ns.rzo.lan. @ IN MX 10 mail.rzo.lan. mail IN A 192.168.122.10 ns IN A 192.168.122.11 postfix IN CNAME mail bind1 IN CNAME ns nano /etc/bind/rzo.private 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 $TTL 86400 $ORIGIN rzo.private. @ IN SOA ns.rzo.private. admin.rzo.private. ( 2023100201 ; serial 21600 ; refresh 10800 ; retry 43200 ; expire 10800 ) ; minimum @ IN NS ns.rzo.private. @ IN MX 10 mail.rzo.private. mail IN A 192.168.122.10 ns IN A 192.168.122.11 postfix IN CNAME mail bind1 IN CNAME ns nano /etc/bind/rzo.lan.inverse 1 2 3 4 5 6 7 8 9 10 11 12 $TTL 86400 @ IN SOA ns.rzo.lan. admin.rzo.lan. ( 2023100101 ; serial 21600 ; refresh 10800 ; retry 43200 ; expire 10800 ) ; minimum @ IN NS ns. 11 IN PTR ns 10 IN PTR mail named-checkzone rzo.lan /etc/bind/rzo.lan named-checkzone rzo.private /etc/bind/rzo.private named-checkzone rzo.lan.inverse /etc/bind/rzo.lan.inverse systemctl restart bind9 test sur machine extérieure - après modification dns\ndig ns.rzo.lan dig mail.rzo.lan dig -x 192.168.122.11 dig -x 192.168.122.10 vm thunderbird # apt install -y thunderbird connexion utilisateur virtuel xeylou\ncliquez sur l\u0026rsquo;image pour zoomer, les formulaires séléctionnez sont ceux que j\u0026rsquo;ai cliqués\nsur une autre VM, mêmes manipulations pour l\u0026rsquo;utilisateur testing\nl\u0026rsquo;envoi et la réception des mails fonctionne\nexemple d\u0026rsquo;envoi d\u0026rsquo;un mail\nle mail peut être visualisé sur la vm postfix/dovecot\nls /opt/messagerie/rzo.private/testing/Maildir/.Sent/cur/ ","date":"2023-09-30","externalUrl":null,"permalink":"/posts/postfix-workshop/","section":"Posts","summary":"installation d\u0026rsquo;un serveur mail mx postfix","title":"postfix workshop","type":"posts"},{"content":" installation d\u0026rsquo;une infrastructure dns bind9 introduction # les deux premiers tp portaient sur l\u0026rsquo;installation d\u0026rsquo;une infrastructure dns avec bind9\nje n\u0026rsquo;ai pas fait les notions \u0026ldquo;transversales\u0026rdquo; : gestion des logs \u0026amp; les acl\npour nous le qcm sur bind9, dovecot, postfix sera le 18 ou le 19 octobre, sur des notions de cours, td, tp\npas de points négatifs, pas de choix multiples -\u0026gt; une seule réponse possible\nexplications # j\u0026rsquo;utilise 3 vm debian 12 : r303-deb12-host1, r303-deb12-bind1 \u0026amp; r303-deb12-bind2\nle réseau local des vm est le 192.168.122.0/24 avec leur passerelle par défaut en 192.168.122.1\n%%{init: {'theme':'dark'}}%% graph TD subgraph 192.168.122.0/24 host1[r303-deb12-host1\n.2] bind1[r303-deb12-bind1\n.3] srv-bind(Service Bind9) srv-bind2(Service Bind9) bind2[r303-deb12-bind2\n.4] gw{NAT\n.1} end wan{WAN} wan --- gw gw --- host1 \u0026 bind1 gw --- bind2 bind1 -.- srv-bind bind2 -.- srv-bind2 j\u0026rsquo;utilise debian par habitude, mr. le prof veut nous faire accèder en ssh à ces vm pour ne pas utiliser l\u0026rsquo;environnement de bureau des ubuntu\nconfiguration initiale # pour éviter d\u0026rsquo;avoir root@debian sur toutes les vm en ssh, je change leur hostname pour avoir root@serveur-bind-1 par exemple\nlors des manipulations en terminal, ça évite de se tromper entre qui est qui \u0026amp; de rentrer une commande sur la mauvaise vm\nNote commande effectuée en permission root sur les 3 vm en changeant nouveau_hostname hostnamectl set-hostname nouveau_hostname \u0026amp;\u0026amp; logout je change aussi les ip des vm de manière statique dans /etc/network/interfaces\nnano /etc/network/interfaces je supprime la ligne indiquant de se référer au dhcp (si elle existe): inet iface enp1s0 dhcp\n\u0026amp;\u0026amp; je rajoute cette configuration selon l\u0026rsquo;interface, ici enp1s0 où X est le dernier octet de l\u0026rsquo;adresse des vm configurées sur le schéma\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 # This file describes the network interfaces available on your system # and how to activate them. For more information, see interfaces(5). source /etc/network/interfaces.d/* # The loopback network interface auto lo iface lo inet loopback # The primary network interface # interface que vous avez auto enp1s0 iface enp1s0 inet static address 192.168.122.X netmask 255.255.255.0 gateway 192.168.122.1 pour me simplifier la connexion en ssh, j\u0026rsquo;autorise l\u0026rsquo;accès au compte root sur les vm - désactivé par défaut par sécurité\nen éditant le fichier /etc/ssh/sshd_config\nNote manipulation effectuée sur les 3 vm nano /etc/ssh/sshd_config en décommentant \u0026amp; changeant la valeur de cette variable\n30 31 32 33 34 35 36 # Authentication #LoginGraceTime 2m PermitRootLogin yes #StrictModes yes #MaxAuthTries 6 #MaxSessions 10 je redémarre le daemon ssh pour prendre la modification en compte\nsystemctl restart sshd je change aussi le mot de passe du compte root des vm\npasswd root pour ne pas trop réflechir avec des ip - je le fais mais une erreur d\u0026rsquo;inattention dans une ip \u0026amp; j\u0026rsquo;y suis pour 4h de deboggage\u0026hellip;\nsur la machine qui va accèder en ssh aux vm, je crée des alias pour juste rentrer ssh bind \u0026amp; arriver sur la vm bind par exemple - j\u0026rsquo;essaye d\u0026rsquo;être \u0026ldquo;fénéant intelligemment\u0026rdquo; :smile:\nNote sur la machine physique nano ~/.ssh/config avec la configuration suivante\n1 2 3 4 5 6 7 8 9 10 11 host host1 Hostname 192.168.122.2 User root host bind1 Hostname 192.168.122.3 User root host bind2 Hostname 192.168.122.4 User root après ça je peux juste faire ssh host1 qui sera l\u0026rsquo;équivalent de ssh root@192.168.122.2\nconf. serveur bind1 # j\u0026rsquo;utiliserai le nom de domaine adehu.com\nj\u0026rsquo;accède au shell du serveur bind\nssh bind1 j\u0026rsquo;installe les paquets nécessaires\napt install -y dbus bind9* dnsutils avant de débuter:\nune zone inverse : on demande au serveur dns -\u0026gt; pour cette adresse ip, tu as quel domaine?\nce qui est l\u0026rsquo;inverse de -\u0026gt; j\u0026rsquo;ai ce nom de domaine, donne-moi son ip associée\ndans la zone inverse, il faut mettre les mêmes enregistrements que ceux dans adehu.com, mais à l\u0026rsquo;envers (vous allez comprendre)\nje définis aussi que ce serveur dns (bind1) est le serveur principal pour ces zones dns\ndans le fichier de gestion des zones /etc/bind/named.conf, sera définit la zone dns \u0026amp; sa zone inverse\nmême si la bonne pratique voudrait qu\u0026rsquo;il inclut un fichier de configuration pour chaque zone\u0026hellip;\nnano /etc/bind/named.conf contenant la configuration suivante\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 // This is the primary configuration file for the BIND DNS server named. // // Please read /usr/share/doc/bind9/README.Debian for information on the // structure of BIND configuration files in Debian, *BEFORE* you customize // this configuration file. // // If you are just adding zones, please do that in /etc/bind/named.conf.local include \u0026#34;/etc/bind/named.conf.options\u0026#34;; include \u0026#34;/etc/bind/named.conf.local\u0026#34;; include \u0026#34;/etc/bind/named.conf.default-zones\u0026#34;; zone \u0026#34;adehu.com\u0026#34; IN { type master; file \u0026#34;/etc/bind/adehu.com\u0026#34;; }; zone \u0026#34;122.168.192.in-addr.arpa\u0026#34; { type master; file \u0026#34;/etc/bind/adehu.com.inverse\u0026#34;; }; on fait référence à des fichiers qui seront la configuration de ces zones\ntype master: ce dns est le serveur dns principal de cette zone\npour vérifier la syntaxe du fichier après l\u0026rsquo;enregistrement\nnamed-checkconf /etc/bind/named.conf le serveur bind1 sait maintenant qu\u0026rsquo;il doit se référer au fichier de configuration /etc/bind/adehu.com pour la gestion de la zone adehu.com qu\u0026rsquo;il gère\nconfiguration de la zone dns adehu.com\nnano /etc/bind/adehu.com 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 $TTL 86400 $ORIGIN adehu.com. @ IN SOA bind1.adehu.com. admin.adehu.com. ( 2023092702 ; serial 21600 ; refresh 10800 ; retry 43200 ; expire 10800 ) ; minimum @ IN NS bind1.adehu.com. @ IN NS bind2.adehu.com. guest.adehu.com. IN NS bind2 bind1 IN A 192.168.122.3 bind2 IN A 192.168.122.4 srv-bind1 IN CNAME bind1 srv-bind2 IN CNAME bind2 la directive $ORIGIN est là pour indiquer le domaine si un hôte est pas totalement défini\n@ IN SOA pour accorder qui a l\u0026rsquo;autorité sur cette zone (ici bind1) avec sa config.\nIN NS pour faire le record d\u0026rsquo;un serveur dns (pour cette zone il y a deux serveurs dns)\nje rajoute un . à la fin des fqdn pour indiquer leur fin (sinon ils répètent leur domain.tld)\nguest.adehu.com. IN NS r303-deb12-bind2 définit un sous domaine \u0026amp; le délègue à bind2 -\u0026gt; si tu veux aller sur le sous-domaine guest.adehu.com, va contacter ce serveur dns\npar contre, sur le deuxième serveur dns (bind2), il faudra lui indiquer qu\u0026rsquo;il gère cette zone (guest.adehu.com)\nIN A record pour définir les adresses ip des machines qu\u0026rsquo;on renseigne (A pour ipv4, AAAA pour ipv6)\nIN CNAME les serveurs bind seront accessibles via bindX.adehu.com où X leur nombre\nles valeurs chiffrées je ne les ai pas sorti de mon chapeau mais de ce tableau d\u0026rsquo;équivalence (secondes -\u0026gt; instances de temps)\nsecondesinstances de temps601 min180030 min36001 heure108003 heures216006 heures4320012 heures864001 jour259200\n3 jours6048001 semaine pour la zone inverse\nnano /etc/bind/adehu.com.inverse 1 2 3 4 5 6 7 8 9 10 11 12 13 $TTL 86400 @ IN SOA bind1.adehu.com. admin.adehu.com. ( 2023092701 ; serial 21600 ; refresh 10800 ; retry 43200 ; expire 10800 ) ; minimum @ IN NS bind1. @ IN NS bind2. 11 IN PTR bind1 12 IN PTR bind2 IN PTR le nombre au début = dernier octet de l\u0026rsquo;ip voulue, on enregistre un pointeur (ptr) vers tel machine\nvérification de la syntaxe\nnamed-checkzone adehu.com /etc/bind/adehu.com named-checkzone adehu.com.inverse /etc/bind/adehu.com.inverse redémarrage du service bind9 pour prendre en compte les modifications\nsystemctl restart bind9 Mettez dans le /etc/resolv.conf de la machine host1 l\u0026rsquo;ip du serveur bind1 pour l\u0026rsquo;avoir en tant que serveur dns nano /etc/resolv.conf 1 nameserver 192.168.122.3 vérification de l\u0026rsquo;installation\ntous les tests en dessous fonctionnent\n# pour tester un domaine: dig domain.tld dig adehu.com # connaitre les serveurs dns gérant un domaine: dig NS domain.tld dig NS adehu.com # résoudre un nom: dig sub-domain.domain.tld dig bind1.adehu.com dig bind2.adehu.com # tester la zone inverse: nslookup ip-machine-a-joindre # ou dig -x nslookup 192.168.122.3 nslookup 192.168.122.4 cependant, je n\u0026rsquo;ai pas testé le sous-domaine guest.adehu.com car pas encore configuré sur le serveur bind2\ndeuxième serveur bind # je vais partager la gestion de la zone adehu.com au deuxième serveur dns r303-deb12-bind2, le serveur bind1 sera le serveur dns primaire (master) \u0026amp; bind2 le secondaire (secondary)\nj\u0026rsquo;autorise alors le transfert de la zone adehu.com vers le serveur bind2 r303-deb12-bind2 par en renseignant son ip\nNote sur r303-deb12-bind1 nano /etc/bind/named.conf 1// This is the primary configuration file for the BIND DNS server named. 2// 3// Please read /usr/share/doc/bind9/README.Debian for information on the 4// structure of BIND configuration files in Debian, *BEFORE* you customize 5// this configuration file. 6// 7// If you are just adding zones, please do that in /etc/bind/named.conf.local 8 9include \u0026#34;/etc/bind/named.conf.options\u0026#34;; 10include \u0026#34;/etc/bind/named.conf.local\u0026#34;; 11include \u0026#34;/etc/bind/named.conf.default-zones\u0026#34;; 12 13zone \u0026#34;adehu.com\u0026#34; IN { 14 type master; 15 file \u0026#34;/etc/bind/adehu.com\u0026#34;; 16 allow-transfer { 192.168.122.4; }; 17}; 18 19zone \u0026#34;122.168.192.in-addr.arpa\u0026#34; { 20 type master; 21 file \u0026#34;/etc/bind/adehu.com.inverse\u0026#34;; 22 allow-transfer { 192.168.122.4; }; 23}; redémarrage du service bind9\nsystemctl restart bind9 de l\u0026rsquo;autre côté, je dois informer au serveur bind2 qu\u0026rsquo;il a cette zone, avec r303-deb12-bind1 en serveur dns maitre\nside note: si une modification est faite sur la zone sur le serveur bind1, elle sera répliquée sur le serveur bind2\nj\u0026rsquo;ajoute aussi le sous domaine qu\u0026rsquo;il lui a été attribué (guest.adehu.com) -\u0026gt; délégation de zone, où il sera le dns primaire\nNote sur r303-deb12-bind2 nano /etc/bind/named.conf 1// This is the primary configuration file for the BIND DNS server named. 2// 3// Please read /usr/share/doc/bind9/README.Debian for information on the 4// structure of BIND configuration files in Debian, *BEFORE* you customize 5// this configuration file. 6// 7// If you are just adding zones, please do that in /etc/bind/named.conf.local 8 9include \u0026#34;/etc/bind/named.conf.options\u0026#34;; 10include \u0026#34;/etc/bind/named.conf.local\u0026#34;; 11include \u0026#34;/etc/bind/named.conf.default-zones\u0026#34;; 12 13zone \u0026#34;adehu.com\u0026#34; IN { 14 type slave; 15 file \u0026#34;/etc/bind/adehu.com\u0026#34;; 16 masters { 192.168.122.3; }; 17}; 18 19zone \u0026#34;122.168.192.in-addr.arpa\u0026#34; { 20 type slave; 21 file \u0026#34;/etc/bind/adehu.com.inverse\u0026#34;; 22 masters { 192.168.122.3; }; 23 24zone \u0026#34;guest.adehu.com\u0026#34; IN { 25 type master; 26 file \u0026#34;/etc/bind/guest.adehu.com\u0026#34;; 27}; on lui renseigne les zones\nà commencer par adehu.com\nnano /etc/bind/adehu.com même configuration qud bind1\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 $TTL 86400 $ORIGIN adehu.com. @ IN SOA bind1.adehu.com. admin.adehu.com. ( 2023092702 ; serial 21600 ; refresh 10800 ; retry 43200 ; expire 10800 ) ; minimum @ IN NS bind1.adehu.com. @ IN NS bind2.adehu.com. guest.adehu.com. IN NS bind2 bind1 IN A 192.168.122.3 bind2 IN A 192.168.122.4 srv-bind1 IN CNAME bind1 srv-bind2 IN CNAME bind2 y compris la zone inverse\nnano /etc/bind/adehu.com.inverse même configuration que bind1\n1 2 3 4 5 6 7 8 9 10 11 12 13 $TTL 86400 @ IN SOA bind1.adehu.com. admin.adehu.com. ( 2023092702\u0026amp; ; serial 21600 ; refresh 10800 ; retry 43200 ; expire 10800 ) ; minimum @ IN NS bind1. @ IN NS bind2. 11 IN PTR bind1 12 IN PTR bind2 vu qu\u0026rsquo;un sous-domaine a été délégué, il faut définir sa zone\nnano /etc/bind/guest.adehu.com 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 $TTL 86400 $ORIGIN guest.adehu.com. @ IN SOA guest.adehu.com. guest.adehu.com. ( 2023092702 ; serial 21600 ; refresh 10800 ; retry 43200 ; expire 10800 ) ; minimum @ IN NS bind2.guest.adehu.com. adehu.com. IN NS bind1.adehu.com. adehu.com. IN NS bind2.adehu.com. bind1.adehu.com. IN A 192.168.122.3 bind2.adehu.com. IN A 192.168.122.4 srv-bind2 IN CNAME bind2 application des modifications\nnamed-checkzone adehu.com /etc/bind/adehu.com named-checkzone adehu.com.inverse /etc/bind/adehu.com.inverse systemctl restart bind9 pour tester le serveur bind2 depuis la machine host1\nnslookup adehu.com 192.168.122.4 nslookup guest.adehu.com 192.168.122.4 ","date":"2023-09-27","externalUrl":null,"permalink":"/posts/bind9-workshop/","section":"Posts","summary":"installation d\u0026rsquo;une infrastructure dns bind9 introduction # les deux premiers tp portaient sur l\u0026rsquo;installation d\u0026rsquo;une infrastructure dns avec bind9","title":"bind9 workshop","type":"posts"},{"content":"","date":"2023-09-01","externalUrl":null,"permalink":"/tags/monitoring/","section":"Tags","summary":"","title":"Monitoring","type":"tags"},{"content":"","date":"2023-09-01","externalUrl":null,"permalink":"/tags/security/","section":"Tags","summary":"","title":"Security","type":"tags"},{"content":" taking a tour \u0026amp; understanding\nvariety of security notions introduction # learning network security, i had to write a post related to it\nthis post aims to learn or clarify hosts \u0026amp; networks security notions/jargon, not covering kinds of threats or attacks\ni used simpler words than the ones found in my research to make it easier to read for non-native english speakers\ni am not an expert by any means, please let me know if i\u0026rsquo;ve said something wrong\nglossary # defining mandatory concepts related to the notions covered\nmalware # malwares are malicious piece of code or software designed to harm or hijack a device or its data by any means\npayload # payload is the part of a malware who responsible for the damages - data exfiltration, making a host unusable, etc.\nvulnerability # vulnerabilities refer to hardware, software or procedures weaknesses that could be exploited by a threat\nthreat # threats are malicious or negative potential events exploiting known or yet unknown vulnerabilities\nthe word threat actor comming from it refers to people behind a malicious incident\nrisk # risks qualifies the probability that a threat exploits a vulnerability causing a critical damage to the host or its neighbours\nrisk = threat * vulnerability * damage\nattack # attacks are the usage exploitation of a vulnerability by a threat actor\nclassification for those are seperated, e.g: human threat, viruses\u0026hellip;\nthreat model # threat modeling is the process of identifying potential vulnerabilities or security flaws, prioritising weaknesses to address or mitigiate to minimize the risks\nendpoint # endpoints are the farrest devices on a network comming from the outside, can be hosts or servers\nendpoint protection # are covered various protections for endpoints/hosts according to many types of threats \u0026amp; attacks\ni only wrote about relevant \u0026amp; still active protection solutions\nhardware side # fde # on the hardware side, full-disk encryption is a very good practice to preserve security \u0026amp; privacy for portable devices\nhaving Luks for all kinds of needs \u0026amp; BitLocker for windows OSs\nthe better \u0026amp; common way to do fde is by using the tpm trusted platform module chip to generate the encryption keys \u0026amp; keeping part of it to itself\nadditionnaly for luks, it uses a master key asked before the boot sequence using a passphrase hash to boot into the OS\ndlp # to minimise data loss (i.e. \u0026ldquo;availability\u0026rdquo; in production use), the threat model could implement a data loss prevention procedure\na usefull data loss model could be the 3-2-1 backup strategy\n3 copies of the data - (or more) 2 backups on different storage media - really helps 1 backup copy offsite - can be cloud, nas\u0026hellip; for personnal use, backuping on two different medias (e.g: a nas \u0026amp; a disk or cloud) can do the job, but please do not underestimate the value of backups in production use\nonce an host has been infected or is showing signs to, doing a quick \u0026amp; tested restoration is very usefull \u0026amp; saves time\nsoftware side # authorisation # authorisation can be associated to permissions\na good practice is to always let the minimal permissions to the users, restricting them to do only what they are intended to\nthat can be a part of the threat model: who can access which ressources\nin other words, when an user is compromised -\u0026gt; what can he access, so what became at risk?\ndisabling the root account is also a good practice for most hosts, prefering a sudoer or proper user permissions\nas always, good passwords are always a most \u0026amp; for the ssh protocol the usage of keys or certificates in highly recommended\nauthentication # using a login \u0026amp; a password cannot verify the identity of the person accessing a ressource for that user\nsince then, human intervention has guaranteed the identity of the person accessing the resource\nback then, simple questions where asked to know if the intended person using the credentials was the one intended - e.g name of its dog, where did he was born, etc.\nthis authentication method was highly subjected to doxing/osint\nnowadays, 2fa is used, living on the intended person\u0026rsquo;s phone or an dedicated hardware device (yubikey)\n2fa can take the form of push notifications (malicious ones can be injected), sms verifications (warning sim swapping attack method) or authenticators codes using the totp protocol\nmfa (multifactor authentication) is also a thing\nos/software side # epp # endpoint protection platform define the suite of technos or solutions used to protect endpoints\nng-av/edr # antivirus (av), next gen antivirus (ngav) \u0026amp; endpoint detection \u0026amp; response (edr)\nare commonly used solutions to protect endpoints\nsources i found says different things about them, so i put ng-avs \u0026amp; edrs together, i wonder if their names are not just a marketing thing for the same solutions\n\u0026ldquo;legacy avs\u0026rdquo; are based in signature recognition to stop known malware file\nan individual hash could be generated for each file. standard avs compare them to a list of malicious files hash to know if the checked file is one of them or not to flag it\nit is only working against file-based attack \u0026amp; new or yet unknown malwares, otherwise it could not be discovered using this method\nvariations of a malware (malformed sinature trick) can also be done, so its bypass the hash check since it is not in the signature database\nngav use behaviour detection on top of the signature recognition, so if a software/program/service activity is suspicious -\u0026gt; the file or its activity can be put in quarantine or be stopped\nsome may introduce sandboxing \u0026amp; ai - machine learning although av \u0026amp; ngav are already well ressources hungry\nedr \u0026amp; ng-avs are very important security solutions since only the endpoint can see the unencrypted ongoing or incomming traffics (e.g. https traffic)\nbe aware that more than one av could lead to more ressource usage \u0026amp; them trying to cancel each other, since they are accessing same files \u0026amp; seeing each other activity\nnetwork solutions # network solutions are preferable so threats or attacks are stopped before reaching the endpoints\nfirewall # firewalling protects networks from unwanted traffic by setting a set of pre-programmed rules\nit can also provide a network segmentation, separating the lan local area network into smaller ones w/ their dedicated rules\nnot to compare w/ software firewalls who applies rules to an host applications only\nproxy # proxy servers could be an intermediate to access the internet in a lan (local area network)\nvery usefull to reduce a network attack surface since all the traffic is going through it\nit can monitor traffic or gather metrics\nit also provide sort of firewalling since you are restricted by what the proxy permit you to access to\nit is also great for privacy since hosts are not directly exposed, the proxy is\nmany use of proxies can be found doing research\nreverse proxy # reverse proxies act the same as normal proxies but for incomming traffic\nendpoints are behind the reverse proxy so that all incomming connexions need to pass through the reverse proxy to access the hosts\nthe advantages are the same\nids \u0026amp; ips # intrusion detection systems \u0026amp; intrusion protection systems\nthe ids \u0026amp; the ips analyse real-time traffic for signature matching known attacks or suspicious behaviour\nthe difference between them is that ips can act as a hardware switch to cut a malicious traffic whereas the ids only raise alerts\nthey are oftenly shipped inside a firewall by some companies\nsoc # security operations center or isoc information security operations center\nis the structure (people, room, screens \u0026amp; devices) where logs are gathered \u0026amp; correlated\npeople are present at full-time to maintain the soc since it is a very important protection mesure (the ciso chief information security officer, analysts, devops/secdevops teams\u0026hellip;)\nthe soc integrate various solutions such as a siem or a soar for example\nthe soc team makes decisions to act on the feedback according to the logs activity\nndr/xdr # network detection \u0026amp; response and extended detection \u0026amp; response\nthe ndr monitor network layer 2-7 traffic, no agent on the endpoints\nxdr tend to gather more informations by installing agents on endpoints to gather data\nxdr seems to be more corporate solutions \u0026amp; focus on properitaty\nndr can be implemented on its own but a xdr may cause friction if it\u0026rsquo;s not the only protection system deployed\nsiem # security information \u0026amp; event manager\nis offenly used in a soc environment, it gather, centralize \u0026amp; organize all logs from various devices\nlogs gathered from the firewalls, network appliances, ids\u0026hellip; can be filtered by the siem since all their informations aren\u0026rsquo;t always relevant\nthe siem is: collecting, aggregating, identifying, categorising \u0026amp; analysing incidents or events\nthe siem needs continuous learning by the security team (this report is normal because we know [\u0026hellip;], it is current that [\u0026hellip;]\u0026hellip;) or by ai (machine learning) to keep categorising the data well but that has more to do with a soar\nsoar # security orchestration, automation \u0026amp; response\ngo a step further than the siem, taking advantage of the automation\ndoing the same job as a siem but go a step futher by automating and orchestrating time-consuming manual tasks of the secops team, so they can speed up on real incident response time\n","date":"2023-09-01","externalUrl":null,"permalink":"/posts/security-notions/","section":"Posts","summary":"taking a tour \u0026amp; understanding","title":"security notions","type":"posts"},{"content":" software management differences\n\u0026amp; package managers for windows software management # highlighting gaps \u0026amp; problems from the non software management in windows\ninstallation # to install a software in windows, an installer needs to be searched in a browser, downloaded (.exe, .msi\u0026hellip;) \u0026amp; executed to download the wanted software\nby downloading an installer externally, the chances to install a wrong software, install additional ones or a malware is increased\nupdates # software updates are individuals, each software must search for its update - background apps, when the computer starts etc.\nnor the Windows Update or the Microsoft Store will check for the external installed software updates (apps you installed)\nuninstallation # most of the time, software can be found in the control panel or in the apps section of the windows settings\nhowever, software installed in non common path are not listed alongside those (standalone or portable applications\u0026hellip;\u0026amp;)\ndependencies installed to use them usually remain after uninstalling the software - how many programs in the control panel are not used\u0026hellip;\nsome improving # the Microsoft Store has improved the software management in windows\nthe software listed are trusted because approved \u0026amp; listed by Microsoft\nsoftware are searched \u0026amp; directly downloaded, no risks to download additional software or execute a malicious program online\nthe software installed from the Microsoft Store can be all updated at once, no background apps etc. (not as catastrophic as each app has its own updates ritual)\nhowever, the ms store apps list doesn\u0026rsquo;t cover all the wanted users apps\nreal improvement # windows, maybe knowning how software are handled on linux, created their package manager\npackage managers are tools used to install \u0026amp; manage software w/ their packages/dependencies\nlinux users use them to quickly install software, update their system, their software \u0026amp; packages whenever they want, and also uninstall software including unused dependencies, folders created for no residuals\u0026hellip;\na package manager is a simpler \u0026amp; cleaner way to manage your system software \u0026amp; updates\npackages managers can also be used in companies to avoid installing software one by one on hundred PCs, run grouped updates, install specific ver. of a software \u0026amp; more\nwindows package managers # package managers can be found for different purposes\nhere are some of them, how to install \u0026amp; use them\nsmooth transition # to switch into a package manager easily, all installed apps can be found in the Control Pannel, under Programs, Uninstall Programs\ncertain other apps can be found in the Settings -\u0026gt; Applications\neither, this command can be launched in an admin. terminal to list installed apps - games not include, just the launchers\nGet-ItemProperty HKLM:\\Software\\Wow6432Node\\Microsoft\\Windows\\CurrentVersion\\Uninstall\\* | Select-Object DisplayName, DisplayVersion, Publisher, InstallDate | Format-Table –AutoSiz to export the list to a file\nGet-ItemProperty HKLM:\\Software\\Wow6432Node\\Microsoft\\Windows\\CurrentVersion\\Uninstall\\* | Select-Object DisplayName, DisplayVersion, Publisher, InstallDate | Format-Table –AutoSize \u0026gt; C:\\programs.txt winget # winget is the windows package manager shipped with windows 11 - can be installed in windows 10 using a command\nadobe products \u0026amp; other microsoft trusted software can be installed quickly \u0026amp; securely through it\nwith vlc for example, instead of opening a web browser, searching vlc, downloading the installer, executing it, clicking next\u0026hellip;\nopen Powershell \u0026amp; run\nwinget install vlc multiple software can be installed at once, to install gimp \u0026amp; vlc for example winget install gimp vlc\nwinget can search wanted packages too, example with gimp\nwinget search gimp list installed packages (yes, usefull, unusual from windows)\nwinget list uninstall one or more packages\nwinget uninstall vlc gimp upgrade one or all packages at once\nwinget upgrade --id Adobe.Acrobat.Reader.64-bit winget upgrade --all configuration can also be exported if moving from a pc to an other\nwinget export packages.json winget import packages.json ninite # leaving the command line, ninite aims to install \u0026amp; update software all at once using a .exe\nvery usefull after a windows installation to download all your software at once if you don\u0026rsquo;t want winget\nrunning it more than once will update the selected software\non their website, software to download can be choosen, from that it will generate a .exe to install them\nselect software to install \u0026 \"Get Your Ninite\" chocolatey # most used package manager in windows, appeared before winget in 2011: chocolatey is a more open package manager\nmore packages are in chocolatey, they are moderated \u0026amp; doesn\u0026rsquo;t contain malware or bloatware\nchocolatey is more open, so more widely used software are present than in winget, those who are not verified yet by windows but by their editors or chocolatey team\na single powershell command can install chocolatey, runned as admin\nSet-ExecutionPolicy Bypass -Scope Process -Force; [System.Net.ServicePointManager]::SecurityProtocol = [System.Net.ServicePointManager]::SecurityProtocol -bor 3072; iex ((New-Object System.Net.WebClient).DownloadString(\u0026#39;https://community.chocolatey.org/install.ps1\u0026#39;)) chocolatey has a strong \u0026amp; native gui called chocolateygui to avoid using commandline compared to winget\nchoco install chocolateygui using it, all software can be upgraded at once, \u0026amp; its telling you an error if it can\u0026rsquo;t (standard installers don\u0026rsquo;t)\nthe commands are similar to winget with the choco command\ni personally use chocolatey when i got to be on windows host \u0026amp; find it more convenient to use, also for new users because of its native gui\nlist installed software, so you can quickly see your unused apps to uninstall or quickly install your software to a new windows host using chocolatey\nchoco list upgrade all packages\nchoco upgrade all or upgrade vlc only\nchoco upgrade vlc and the ultimate command to remove a software with its dependencies if not use by other software - those commands are the same\nchoco uninstall package --removedependencies choco uninstall package -x if an other software uses the removed one dependencies, chocolatey doesn\u0026rsquo;t uninstall them \u0026amp; tells you it didn\u0026rsquo;t\nbonus macos # the macos software management is different from the windows one\nalthough, homebrew has the same role as chocolatey does for windows\n","date":"2023-08-21","externalUrl":null,"permalink":"/posts/win-pkgs-mngers/","section":"Posts","summary":"software management differences","title":"software in windows","type":"posts"},{"content":"","date":"2023-08-19","externalUrl":null,"permalink":"/tags/cheat-sheet/","section":"Tags","summary":"","title":"Cheat-Sheet","type":"tags"},{"content":" introduction # here i expose my ssh usages \u0026amp; some advanced notions about it\ni\u0026rsquo;ll speak about the ssh protocol as the openssh implementation\ni\u0026rsquo;m tempted to write my articles in lower case only as i usually write so outside\nread this article like a cheat sheet\nfundamentals # secure shell - ssh, is a very versatile protocol but generally used to access a remote server command line securely\nencapsulate in tcp/ip use port tcp/22 by default use asymetric cryptography the first time accessing a remote ssh host, its public key fingerprint is prompted to know if you are accessing the wanted host - security reasons, prevent MitM attacks - asking you if you trust it or not\nif yes, the fingerprint is paste in your ~/.ssh/known_hosts w/ the associate ip address \u0026amp; encryption protocol; its now trusted by your local machine\nmodifications # on the ssh server side, connexions behaviour can be modified in /etc/ssh/sshd_config\n(sshd stands for ssh daemon)\nbasic ssh setup let you connect to a host entering an username \u0026amp; a password beside root\nif modifications is made, for the changes to take effect: the sshd service needs to be restarted\nsystemctl restart sshd for hosts using systemd, like debian distros\ngood practices # change the ssh access port from the port 22\ncheck if the root login is disabled (yes by default)\nusing ssh keys or certificates (authentication) + username \u0026amp; password (authorisation)\nuse differents keys to access different servers\nuse ~/.ssh/config to easily manage keys \u0026amp; remote hosts\nuse a passphrase for your private keys\nuse an ssh bastion to centralise your connections from the outside\nkeys # the server has a public key that everyone can see, only you have the private key to connect to the server; public key -\u0026gt; the lock, private key -\u0026gt; the key\u0026hellip;\nprivate \u0026amp; public keys are generated simultaneously, various encryption algorithms could be choosen\nprivate keys default location is ~/.ssh in your local machine - perfectly fine with it\nw/ openssl, this command brings forms to fill to create a public \u0026amp; a private key pair\nssh-keygen # to generate keys to automate or create many at once w/out filling the forms:\n-C can be used to add a comment to a key\n-t to choose the encryption algorithm - rsa by default\n-b number of bytes, the more the better encryption\n-f the location, usefull when creating many keys at once\n-N \u0026quot;\u0026quot; specify a passphrase, replace what\u0026rsquo;s inside \u0026quot;\u0026quot;\npushing a public key to a remote host, after running the ssh-keygen command - make sure an ssh server is running on the remote host \u0026amp; that you have login for it\nssh-copy-id -i path/to/key.pub username@remotehost or\ncat path/to/key.pub | ssh username@remotehost \u0026#34;mkdir -p ~/.ssh \u0026amp;\u0026amp; cat \u0026gt;\u0026gt; ~/.ssh/authorized_keys\u0026#34; passphrases # passphrases can be added to private ssh keys, preventing the usage of the key if stolen\nconfig file # ~/.ssh/config serve the ssh client to manage its remote hosts\nit simplifies your connexions, since you only use to do ssh debian-vm for example\nHost abitraryname Hostname remotehost User username Port sshport IdentityFile /path/to/privatekey after changes, no need to restart a service\nssh abitraryname certificates # works in the same way tls/ssl does for https\nused to scale ssh, usefull to create a limited time access\nafter creating a public \u0026amp; a private key (saw in keys), those can be signed w/ a Certificate Authority (CA) certificate\nssh-keygen -s hostca -I hostname.domain.tld -h -n hostname.domain.tld -V +52w key.pub -s hostca specify the file name of the CA private key\n-I hostname.domain.tld the certificate\u0026rsquo;s identity\n-h specify its an host certificate, not an user one\n-n hostname.domain.tld url to access the future host\n-V +52w certificates\u0026rsquo;s validity period (52 weeks)\n(a passphrase can be asked)\nkey-cert.pub should be generated\nto use it, paste the the ca to the /etc/ssh folder on the local host for example\nand edit in the /etc/ssh/sshd_config file:\nHostCertificate /etc/ssh/key-cert.pub the remote host now present a certificate to anyone who connects\nto the client side, trust the ca in `$HOME/.ssh/know_hosts\n@cert-authority *.domain.tld ssh-rsa \u0026lt;hostca.pub content\u0026gt; file transfering # ways to transfer ressources to \u0026amp; from a remote host\nfrom a remote host # gather a file from a remote host\nscp username@remotehost:/remote/path/to/file . gather a folder from a remote host\nscp -r username@remotehost:/remote/path . synchronising files from a remote host using rsync\nrsync username@remotehost:/remote/path/to/file . rsync -r username@remotehost:/remote/path . to a remote host # send a file to a remote host\nscp filename username@remotehost:/remote/path send a folder to a remote host\nscp -r directoryname username@remotehost:/remote/path rsyncing\nrsync filename username@remote-host:/remote/path rsync -r directoryname username@remote-host:/remote/path mount a remote folder # mount a remote directory on local system w/ sshfs (ssh file system)\napt install -y sshfs # depends on your package manager mkdir mount-dir mount the remote directory in the created folder\nsshfs username@remote-host:/remote/path mount-dir changes in the mount-dir will also be made in remote-host:/remote/path\nto unmount it\numount mount-dir sftp # ssh file transfer protocol, or secure file transfer protocol\ncan be used with the sftp command to open a remote shell\nsftp username@remotehost can navigate with pwd, ls, cd \u0026amp; use get or put to gather or send ressources\nget filename put filename or\nget /path/to/remote/file /path/to/local/directory put /path/to/local/file /path/to/remote/directory a gui like filezilla for an easier transfer experience (gui) can be done\nx11 forwarding # use remote app gui on local host\nconfig remote server # run with root or sudoer\napt install -y xauth # to forward x11 packets, depends pkgs manager allowing x11 fowarding in /etc/ssh/sshd_config by removing #\n87#AllowAgentForwarding yes 88#AllowTcpForwarding yes 89#GatewayPorts no 90X11Forwarding yes 91#X11DisplayOffset 10 92#X11UseLocalhost yes 93#PermitTTY yes systemctl restart sshd ssh into it \u0026amp; try launching xapplications\ndepending on the remote server configuration, some extra work could be intended\nssh tunneling # to access specific ressources, vpns expose an entire network which cannot be relevant for security reasons\nssh tunneling encapsulate a layer 3-7 traffic between 2 hosts over ssh\nssh encryption is added to the communication - so that if an unsecured communication is used, it is encrypted\nit can also be used to bypass firewall restrictions by fowarding ports\nuncontrolled or unmonitored tunnels can be used as backdoors, for data exfiltration, bouncing attacks \u0026amp; more\nlocal fowarding # forward a port from a ssh client to a ssh server (launched from the ssh client)\nextremely usefull to access a remote service denyied by a firewall, it needs the remote host to be accessible with ssh\n%%{init: {'theme':'dark'}}%% graph LR a(local machine) b(firewall) c(remote host) a---b b--\u003ec let\u0026rsquo;s say you have a raspberry pi at 192.168.1.12 (remote host) w/ ssh access via the pi user\nit shosting a web server locally on its 5000 port \u0026amp; you want to access it locally through your machine\nssh -N -L 127.0.0.1:8080:127.0.0.1:5000 pi@192.168.1.12 ssh -N -L 8080:127.0.0.1:5000 pi@192.168.1.12 -N prevents from running an active ssh session\nall traffic (http requests) sent to localhost:8080 on local machine will be forwarded to raspberry pi\u0026rsquo;s 5000 port - responses sended back to you\nLocalForward variable can be edited in the config file to avoid putting it every connexion\nreverse ssh tunnels # also called remote ssh tunnels or ssh remote forwarding\nforward a port on a remote host (ssh server) to a port on a local machine (ssh client)\ninitialised by the remote server\nused to access a service hosted on a remote local network, from another network (or internet)\n%%{init: {'theme':'dark'}}%% graph LR a(remote sever) b(firewall) c(local machine) a---b b--\u003ec widely use to exploit systems on private networks\nlet\u0026rsquo;s say: the remote server is locally running a web server on its port 80, its local network address is 192.168.1.23\nthe local machine public ip address is 8.8.8.8 - google one \u0026amp; accessible w/ ssh\nssh -N -R localhost:8080:192.168.1.23:80 root@8.8.8.8 ssh -N -R 8080:192.168.1.23:80 root@8.8.8.8 the service running the remote server port 80 will be accessible by the local machine loopback address on port 8080\nprevent tunnels # PermitTunnel no can be changed in /etc/ssh/sshd_config to prevent tunnels creation\nssh bastions # can be called ssh jump servers, ssh proxies or ssh agent forwarding\na single server accessible via ssh from the internet to redirect ssh sessions to others hosts\nusefull to centralise \u0026amp; secure ssh connexions in a corporate network to reduce the \u0026ldquo;attack surface\u0026rdquo; to just one machine\nteleport is an opensource solution if not using openssh\nadvices # only the ssh port should be accessible for incomming connexions the ssh port is changed from 22 root user is disabled be very aware of the security implementations prevent users to use an ssh active session into the bastion itself other purposes # can be used to encapsulate data, doing other services than transporting ssh packets\ncan be used as a \u0026ldquo;vpn\u0026rdquo;, doing dynamic ssh port forwarding \u0026amp; encapsulate your data w/out exposing an entire network (ssh + socks5 proxy)\ncommand # ssh -J bastionaddress username@remotehost -J parameter can be avoided by configuring the ProxyJump permanently in config file\nparameters saw in config file can be added too\nHost arbitraryname ProxyJump bastionaddress creation of an ssh user that cannot ssh into the bastion itself, called bastionuser in /etc/ssh/sshd_config\ngive this user to anyone using the bastion\nMatch User bastionuser PermitTTY no X11Forwarding no PermitTunnel no GatewayPorts no ForceCommand /usr/sbin/nologin then modify the parameters\nssh -J bastionuser@bastionaddress username@remotehost for the ~/.ssh/config\nHost remotehost ProxyJump bastionuser@bastionaddress chrooting # change root (chroot) method changes appareant root directory for the running user to a root directory called a chrooting jail\nusefull when giving access to untrusted or unmonitored users\nssh support chrooting by restricting an ssh session to a directory\nyou can create a fancy one manually but it is very long, for each user\nrssh is a simpler way to do so\ncreate a new user with the /usr/bin/rssh shell\nuseradd -m -d /home/chrooteduser -s /usr/bin/rssh chrooteduser passwd chrooteduser or change existing user shell to /usr/bin/rssh\nusermod -s /usr/bin/rssh chrooteruser works for sftp \u0026amp; scp\ndnssec # ssh use tofu trust on first use, it trusts the ssh server the first time connecting to it\nso if someone tried to impersonate the remote host identity or the host change, its fingerprint will be different \u0026amp; a warning will pop up saying that\u0026rsquo;s not the wanted server\nif targetted by a man-in-the-middle attack the first connexion, you could be at risk using ssh connexion\ndnssec has many features to improve the standard \u0026amp; old dns protocol, one of which is: dns answers are not tampered\nit is possible that an attacker can hijack ssh connexions \u0026amp; create valid dnssec responses, but less likely\nuse ssh-keygen as usual w/ an url using dnssec \u0026amp; a . at its end to stop the domain for beeing repeated twice\nssh-keygen subdomain.domainwithdnssec.tld. then\nssh -o VerifyHostKeyDNS=yes subdomain.domainwithdnssec.tld. ","date":"2023-08-19","externalUrl":null,"permalink":"/posts/ssh-cheat-sheet/","section":"Posts","summary":"introduction # here i expose my ssh usages \u0026amp; some advanced notions about it","title":"ssh explored","type":"posts"},{"content":" overviewing centreon it \u0026amp; getting fully hands-on introduction # The last article in this series will be devoted to discover \u0026amp; use Centreon IT.\nFeel free to correct me by email if i\u0026rsquo;ve said something wrong.\npresentation # Centreon IT is a french open-source based monitoring solution.\nIt is highly inspired by Nagios, since it was a Nagios frontend at its beginning.\nCentreon\u0026rsquo;s solutions has the same Nagios\u0026rsquo; plugins \u0026amp; hosts systems but can keep their hands on the plugins with their repository - where the community can freely publish them for Nagios.\nCentreon is a profit-oriented company who has a business model based on licensing the number of hosts monitored.\nThe free solution called Centreon IT-100 is licensed for 100 monitored hosts only - their Free Trial. Other differences with the commercial editions are listed in their comparison table.\nnamely # Informations on how Centreon IT works \u0026amp; its specific features.\norganisation # Centreon claims their solutions can be hosted on site, called OnPrem, or cloud-based, called Cloud.\nCentreon instances always works with a Central Server, called centreon-central used to configure monitoring, display \u0026amp; operate the collected data.\nTo monitor multiple sites, instances can be deployed \u0026amp; attached to the Central Server, the Remote Servers.\nMonitored data is gathered using Pollers, attached to the Central or a Remote Server.\nHere is what a Centreon OnPrem distributed architecture should looks like according to Centreon.\n%%{init: {'theme':'dark'}}%% graph TD central[Central Server] remote0[Remote Server] remote1[Remote Server] remote2[Remote Server] poller0((Poller)) poller1((Poller)) poller2((Poller)) poller3((Poller)) poller4((Poller)) poller5((Poller)) central---remote0 \u0026 remote1 \u0026 remote2 remote0---poller0 \u0026 poller1 remote1---poller2 \u0026 poller3 remote2---poller4 \u0026 poller5 The Centreon Cloud architecture does away with Remote Servers, as Pollers are connected to the Central Server via the cloud - using a vpn.\n%%{init: {'theme':'dark'}}%% graph TD central[Central Server] poller0((Poller)) poller1((Poller)) poller2((Poller)) central --- poller0 \u0026 poller1 \u0026 poller2 hosting # Centreon documentation guides to host onprem \u0026amp; cloud solutions on different supports.\nFor an overview, they give *.ovf \u0026amp; *.ova images for virtual box \u0026amp; vmware respectively.\nInstallations alongside gnu/linux distros is preferable for production use.\nThe documentation guides it for RHEL, Alma/Oracle/Rocky Linux since they are rhel based distros - (or \u0026ldquo;were\u0026rdquo; since rhel closed their source).\nLess attention is putted on Debian, the documentation is deprecated for it.\nIn the past - until ver. 21.10, they used to create *.iso images to install their solutions alongside centos.\nconnectors \u0026amp; plugins # Data collection performed by Centreon models called Monitoring Connectors which have Plugins assets.\nPlugins have the same function as Nagios ones.\nInstalled \u0026amp; used by pollers, they are sets of commands to monitor various kinds of metrics, on differents type of hosts regarding many protocols.\nPlugins \u0026amp; connectors are maintained in their centreon-plugins \u0026amp; centreon-connectors repositories, where it seems community can contribute.\nAlthough it\u0026rsquo;s opensource, a license is required to access the full Plugin Pack on their solutions.\ndeploying # Installing Centreon IT-100, doing a simple windows \u0026amp; linux hosts monitoring.\nrequirements # The infrastructure size depends on the number of hosts to monitor.\nCentreon recommends using lvm to manage their file systems - working fine without, but should be planned for production use.\nA stand-alone central server is used under 500 hosts. Pollers every 500 hosts are expected with a database server if more than 2'500 hosts.\nFor production use, it would be a good idea to think about scalability.\nSince there would be too much information to display (partitionning, specs, infrastructure), i let you refer to their infrastructure sizes charts.\ninfrastructure # An infrastructure similar to that used in the nagios article will be deployed.\nFollowing the requirements - partially since it is not for production use, a stand-alone Central server will be deployed with its poller.\nHere is what the used infrastructure looks like.\n%%{init: {'theme':'dark'}}%% graph TD subgraph lan[LAN] router{Router} switch[Switch] centreon(Centreon Central Server\n192.168.122.166) linux(Debian Host\n192.168.122.164) win(Windows Host\n192.168.122.251) mariadb[(MariaDB server)] poller((Poller)) end wan{WAN}---router router---switch switch---centreon switch---linux switch---win centreon-.-mariadb \u0026 poller installation # Centreon IT will be installed without license on Debian 11.\nI made an installation script available on Github.\nThis script installs Centreon IT from added Centreon\u0026rsquo;s apt repositories \u0026amp; install a secured mysql server through mariadb.\nTo execute it, run the following commands.\nmkdir testing \u0026amp;\u0026amp; cd testing wget https://raw.githubusercontent.com/xeylou/centreon-it-overview/main/debian-centreon-install.sh chmod +x debian-centreon-install.sh ./debian-centreon-install.sh Installation can be resumed going on the Centreon web interface http://192.168.122.166.\n(cannot highlight forms natively, so i specify the changes, otherwise i just do next, install or finish)\nMore dependencies than the ones loaded could be presented as Not loaded for debugging (if not using the script).\nCreation of an admin account for the Centreon interface.\nConnexion to the db server. The root password was asked \u0026amp; created by the script at the end.\nUsed localhost (so 127.0.0.1 or ::1) for the db server ip address, since its hosted on the same host as the future centreon central server.\nCreation of a db user to perform data querries - for security purposes, not doign them with an admin one.\nLogin created step 5 Admin information.\nThis is the after-loggin page.\nAfter the installation, the Central server poller is not working.\nAdditionnal steps are required to start monitoring.\nGo to the poller section to see it.\nNeed to click on Export configuration.\nSelect the Central poller.\nCheck Move Export File.\nThen Export.\nAfter that, run the following commands, keep their order without modifying them.\nsystemctl restart cbd centengine systemctl restart gorgoned systemctl start snmptrapd centreontrapd systemctl start snmpd Then the poller starts working.\n(the red circle at top left, to the right of Pollers logo disappears later, see screenshots below)\nsnmp plugins # Centreon recommends using their snmp implementation plugins to gather metrics - cpu load, memory usage etc.\nUsage of the snmp protocol garantees the monitoring to work as intended since the protocol is universal - rather than installing an agent.\nPlugins can be added using the web interface or by using the system package manager (dnf for rhel based distros \u0026amp; apt for the debian family).\nHere is the installation of the needed snmp plugins using the web interface.\nAdding the linux snmp plugin clicking +.\nBase Pack is an expected dependency that will be installed choosing Apply.\nDoing the same for windows snmp plugin, no more dependency needed.\nResult.\nOn wanted monitored hosts, snmp must be configured and working.\nlinux host # Note I\u0026rsquo;ve explained what were done with snmp rather than just throwing you my script as you may need this explainations to monitor other devices like switches or routers. (which doesn\u0026rsquo;t mean i haven\u0026rsquo;t made one) For our needs, according to the debian snmp page, a repo needs to be added to /etc/apt/source.list.\n1# deb cdrom:[Debian GNU/Linux 11.7.0 _Bullseye_ - Official amd64 NETINST 20230429-11:49]/ bullseye main 2 3#deb cdrom:[Debian GNU/Linux 11.7.0 _Bullseye_ - Official amd64 NETINST 20230429-11:49]/ bullseye main 4 5deb http://deb.debian.org/debian/ bullseye main 6deb-src http://deb.debian.org/debian/ bullseye main 7 8deb http://security.debian.org/debian-security bullseye-security main 9deb-src http://security.debian.org/debian-security bullseye-security main 10 11# bullseye-updates, to get updates before a point release is made; 12# see https://www.debian.org/doc/manuals/debian-reference/ch02.en.html#_updates_and_backports 13deb http://deb.debian.org/debian/ bullseye-updates main 14deb-src http://deb.debian.org/debian/ bullseye-updates main 15 16# This system was installed using small removable media 17# (e.g. netinst, live or single CD). The matching \u0026#34;deb cdrom\u0026#34; 18# entries were disabled at the end of the installation process. 19# For information about how to configure apt package sources, 20# see the sources.list(5) manual. 21 22# snmp needs 23deb http://httpredir.debian.org/debian bullseye contrib non-free After that, the needed packages can be installed.\napt update apt install -y snmp snmptrapd snmp-mibs-downloader Checking if the snmp service is running properly.\nsystemctl status snmpd If not, it needs to be started.\nsystemctl start snmpd Before making changes to the snmp daemon configuration file /etc/snmp/snmpd.conf, a backup is always welcome.\ncp /etc/snmp/snmpd.conf{,.old} The snmp protocol will listen for connections on all interfaces on port 161 udp for ipv4 \u0026amp; ipv6.\nSNMP will wait for a specific ip address under a certain community called public here.\nModifications are done in /etc/snmp/snmpd.conf.\n41# agentaddress: The IP address and port number that the agent will listen on. 42# By default the agent listens to any and all traffic from any 43# interface on the default SNMP port (161). This allows you to 44# specify which address, interface, transport type and port(s) that you 45# want the agent to listen on. Multiple definitions of this token 46# are concatenated together (using \u0026#39;:\u0026#39;s). 47# arguments: [transport:]port[@interface/address],... 48 49agentaddress udp:0.0.0.0:161,udp6:[::]:161 67# rocommunity: a SNMPv1/SNMPv2c read-only access community name 68# arguments: community [default|hostname|network/bits] [oid | -V view] 69 70# Read-only access to everyone to the systemonly view 71# rocommunity public default -V systemonly 72# rocommunity6 public default -V systemonly 73rocommunity public 192.168.122.166 After that, the snmp service needs to be restarted.\nsystemctl restart snmpd This command can be run from the Centreon Central Server to check if the configuration is working.\nsnmpwalk -v2c 192.168.122.164 -c public If it does, a lot of text will be displayed rather than this output: Timeout: No Response from 192.168.122.164.\n(if you are working with snmp layer: this command retrieves records from mib by going through each oid running automatic getnext requests, so you don\u0026rsquo;t need a command for each oid or node, on snmp ver. 2c asked with \u0026ldquo;public\u0026rdquo; community)\nwindows host # The windows host is a windows server.\nThe snmp protocol will be enabled on it, authorizing only the centron-central to communicate via a community named public.\nOn the Server Manager window.\n(here i can nicely highlight the forms)\nSelect the hostname of the windows server.\nNo need to add anything, just go Next.\nSearch for the SNMP Service \u0026amp; enable SNMP WMI Provider.\nRight after that go Next.\nThe snmp service needs to be configured in the Server Manager window.\nFind the SNMP Service among the services.\nAdd a community, here public, the same as the one configured on the debian host.\nRead Only is preferable because nothing has to be changed, just the metrics to be gathered.\nThe Centreon server needs to be trusted by entering its ip address.\nLet\u0026rsquo;s click Ok (does Apply \u0026amp; quit).\nThen Restart the service to make the changes take effect.\nThe same command used to check the connectivity of the debian host can be used for the windows one, changing the ip address.\nsnmpwalk -v2c 192.168.122.251 -c public adding hosts # Before adding the hosts to Centreon, it would be pleasant to check their snmp connectivity.\nsnmpwalk -v2c 192.168.122.251 -c public snmpwalk -v2c 192.168.122.164 -c public If the Centreon server can reach them, they can be added to its interface.\nGo to the Hosts configuration.\nClick on Add.\nFilling with the informations for debian host \u0026amp; some arbitraty ones.\nSave.\n(the Default equals Yes for the two cases)\nDoing the same for the windows host informations.\nThe host are added, should looks like so.\nThe pollers need to actualize their configuration files to starts monitoring the hosts.\n(note the red Yes on Conf Changed) Export the configuration in a file for pollers but this time also restart them.\nTo see the hosts \u0026amp; their services status.\nAfter 5 minutes or a Force check.\nIncomming ping (echo requests) are blocked by the windows firewall by default in windows client \u0026amp; server.\nAlthough it is marked as critical, it doesn\u0026rsquo;t shows up like so in the services section at the top left\u0026hellip;\nadding services # More services can be monitored by adding them into the centreon interface.\nClick on Add. Services to monitor can be added according to what plugins are installed in the Centreon server.\nThe sheet with an eye is a small documentation on the command arguments, parameters, etc.\nThe Default options are Yes in the three cases.\nAn then export the configuration \u0026amp; restart the pollers to make changes take effect, like did at the end of adding hosts.\n(to avoid putting a third time the captures how to do it)\ndebugging # Passives checks commands can be seen, helping a lot for debugging.\nIt can also helps for active monitoring without dealing with the Centreon interface.\nHere is how to do so with the swap services.\nThe syntax is the same for the windows \u0026amp; the linux smp plugins except the --plugin option.\nThe services commands syntax are the same, the --mode option change for cpu, load, memory, uptime, etc.\nclose # Here are some commands that helped me (hope can help you) for debugging - apart from connectivity debugging, because i had to debug a lot compared to itop or nagios\nsystemctl status cbd systemctl status gorgoned systemctl status centreon systemctl status centengine systemctl status snmptrapd (btw the centreon service has never been active\u0026hellip;)\nThere are many more services to know \u0026amp; check to understand a problem at the beginning.\nIn Nagios, for the same kind of interface (checking hosts services) you just have the nagios service to check for errors.\nFor centreon, the gathering, the processing, the display parts \u0026amp; more are seperate ones.\nIt\u0026rsquo;s better seperating parts of codes for debugging or reliability, but having a single service that reports all problems can be pleasant (or just not so many services).\nI got hard times to find were a problem could come from sometimes, since the numbers of potential services problem was huge.\nI also understand that centreon as more features (graphs etc.) than nagios base, not xi.\nCentreon uses nagios plugins, in the same directory as nagios does by default\u0026hellip;\nNagios has a page dedicated to CVEs to prove their concern \u0026amp; patches. There may be one, but i haven\u0026rsquo;t found a \u0026ldquo;security concern\u0026rdquo; or issues page\u0026quot; for Centreon.\nThat\u0026rsquo;s disappointing since monitoring systems needs to be very aware of their security.\nCentreon systems were also targetted by russian attackers (article 1, article 2).\nIt is a very good idea to display the command used to check a service, i think i hadn\u0026rsquo;t seen that in nagios.\n","date":"2023-08-12","externalUrl":null,"permalink":"/posts/centreon-it-overview/","section":"Posts","summary":"overviewing centreon it \u0026amp; getting fully hands-on introduction # The last article in this series will be devoted to discover \u0026amp; use Centreon IT.","title":"centreon it overview","type":"posts"},{"content":"","date":"2023-08-12","externalUrl":null,"permalink":"/series/exploring-monitoring-solutions/","section":"Series","summary":"","title":"Exploring Monitoring Solutions","type":"series"},{"content":"","date":"2023-08-12","externalUrl":null,"permalink":"/tags/open-source/","section":"Tags","summary":"","title":"Open-Source","type":"tags"},{"content":" combodo itop tour \u0026amp; creating a living\nit service delivery infrastructure introduction # As with Nagios, i dived into Combodo iTop solution.\nEven though it is not a host monitoring solution, it can be a part of a monitoring infrastructure.\nI had harder time getting into it due to the notions to lean \u0026amp; to consider, inside \u0026amp; outside itop to use it properly.\nSo once again, i\u0026rsquo;d be very grateful if you\u0026rsquo;d consider correcting me if i said someting wrong.\nglossary # Defining mandatory acronyms for this post.\nITSM - IT Service Management\nType of tool usually used by companies to organise \u0026amp; deliver their IT services to their departments or to other companies. They can integrate monitoring tools or a help desk ticketing system for example.\nCMDB - Configuration Management Database\nTerm to define a database used to store \u0026amp; organise the hardware items \u0026amp; the software assets of a company or someone.\nITIL - Information Technology Infrastructure Library\nSet of relevant IT practices describing processes, procedures or actions for IT related operations like system administration or itsm management.\npresentation # Combodo is a 13-year-old french company who created itop, an open source, itil based, itsm \u0026amp; cmdb solution.\nThey are a profit based company, they created 2 non-free versions of itop for business purposes: essentials \u0026amp; professional/enterprise.\nThey also provide free \u0026amp; non-free external software to enhance itop utilisation like a front-end customiser or a network related manager; as weel as consultants.\nitop is typically used by the IT department of a company to organise services \u0026amp; implement a help desk ticketing system to the other departments.\nIt is also used by companies to deliver IT services to other companies as a service provider.\nunderstandings # Reviewing my understanding of itop\u0026rsquo;s main features.\nfundamentals # itop is based on apache, php, graphviz \u0026amp; mysql. However, it can run on nginx instead of apache with extra work.\nThe documentation is made for anyone who is susceptible to use itop.\ncmdb # The cmdb is the core of itop.\nThe cmd works with Objects, which are groups of Instances sharing the same patern.\n(considering the \u0026ldquo;Persons\u0026rdquo; object, each instance of this object would have the same patern: a name, a surname, an age etc.)\nThe cmdb can receive a populated *.csv file to create multiples instances of an object at once. (instead of entering one by one every member of a company for example)\nitop can receive custom objects but their implementation is not guided. The default ones are created without instances.\nObjects \u0026amp; instances are stored in the MySQL database.\nitsm # The itsm is integrated with the ticket management system \u0026amp; will be described using the itil way.\nWhen installing, itop proposes two ways to implement it: to deliver services to departments or to other companies; saw at the end of the presentation.\nThe itsm provides two types of tickets for end users: Users requests \u0026amp; Incidents.\nMandatory objects are needed to use them: Services, Contracts \u0026amp; SLAs.\nHere are their purposes \u0026amp; how they are related.\nServices\nAre defining what is provided by the service provider (IT department or company). Called to generate incidents or to supply users requests. Providers contracts are required.\nContracts\nSplited in Customer \u0026amp; Provider contracts. Customer one defines service(s) provided to/pucharsed by the customer + the SLAs. Provider one links internal ressources (CIs) used for the service(s) provided.\nSLTs - Service Level Target\nDefine metrics agreements between customers \u0026amp; providers. Two by default: TTO - Time To Own: time to take a ticket into account \u0026amp; TTR - Time To Resolve a ticket after creating.\nSLAs - Service Level Agreement\nGroup of SLTs defining the agreement between a provider \u0026amp; a customer for a given set of services.\nWhen a customer creates a ticket, it can select the service amongst the list of services defined for this customer.\nTickets deadlines are computed depending on the SLA signed with the customer.\ndefault objects # Native objects in itop are created during the installation process.\nThey should be used because related to itop principles.\nThe mandatory objects are covered here, many more can be used \u0026amp; discovered exploring itop.\nOrganizations\nCan be used for two purposes: name the different departments of a company when itop is used to deliver IT services within a company, or name the different companies a company is delivering IT services to.\nLocations\nAre used to group objects by geography - servers, organisations etc. A hierachy can be applied, locations can be linked to parents locations (example: inside the company A, there is room A \u0026amp; room B in which have differents servers in racks A \u0026amp; racks B)\nPersons\nDefine the persons contacts \u0026amp; responsabilities regarding the IT services delivered. Can be deployed using Profiles to quickly assign permissions (to the members of a department or a company).\nTeams\nUsefull to define permissions easier - all the HR \u0026amp; finance teams can access to\u0026hellip; -. Can also help the customer to communicate using the ticketing system.\nCIs - Configuration Items\nDescribe hardware devices: racks, pdus, network devices, servers, personal computers, hypervisors, vms etc. Templates are available for a large type of CIs.\nSoftware Installed\nPresent to easily index software installed on devices, licences \u0026amp; so on.\nServices\nObject used to define what actions or access is delivered as a service to a customer. Can be subcategorised - service A contains sub-service B \u0026amp; sub-service C.\nobjects agencement # Objects are related to each others by different means.\nI made graphs to show the links between them, or tried to.\nGraphs are generated using the following rules:\nRectangles are highest objects. Rounded objects are those receiving links. Text in lowercaps are instructions, uppercaps are objects name. Persons integrate Teams according to their Roles.\ngraph LR A[Persons] --\u003e|Roles| B(Teams) Teams belongs to Organizations.\ngraph LR A[Teams] --\u003e|belongs to| B(Organizations) Organizations are linked to Locations.\ngraph LR A[Organizations] --\u003e|are located| B(Locations) Regarding to only these objects, links can be created.\n(Persons -\u0026gt; Teams -\u0026gt; Organizations -\u0026gt; Locations)\nBefore doing that, there are links between objects covered in default objects.\nOrganizations are owning CIs. CIs are exposed to Services \u0026amp; are ruled by Provider Contracts. They can be related to Documents \u0026amp; appear in Tickets.\ngraph LR B[Organizations] --\u003e|owning| A(CIs) A --\u003e|exposed to| C(Services) D[Provider Contracts] --\u003e|rule| A A --\u003e|appear in| E(Tickets) A --\u003e|related to| F(Documents) Relations for Documents.\ngraph LR C[Organizations] --\u003e|owning| A(Documents) A --\u003e|used for| D(Contracts) D --\u003e|defining| A A --\u003e|give informations| F(CIs) A --\u003e|linked to| E(Services) All objects have relations to others at some point by different ways.\nIn addition to this, objects\u0026rsquo; instances have their own properties changing the relations between objects according to their needs.\nIt would be meaningless to create decent relations graphs for all objects, since their dependencies \u0026amp; relationships are to massive \u0026amp; could change each instance.\nDo not refer to this graph. Please read above. graph LR subgraph iTop Company View A[Persons] --\u003e|Roles| B(Teams) B --\u003e|parts of| C(Organizations) C --\u003e|are located| I(Locations) C --\u003e|owning| D(CIs) D --\u003e|related to| E D --\u003e|exposed to| G(Services) H(Provider Contracts) --\u003e|rule| D D --\u003e|appear in| F C --\u003e|owning| E(Documents) E --\u003e|used for| H H --\u003e|defining| E E --\u003e|linked to| G E --\u003e|give informations| D A --\u003e|see activity| D A --\u003e|attached to| F(Tickets) J[Other Objects] --\u003e|give properties| D J --\u003e|structure| E end Even though this graph seems valid for the most part, itop has many more objects than the ones covered. Links between them should be discovered \u0026amp; created using the frontend.\nimplementation # This sections will implement itop following a companies charts \u0026amp; an arbitrary infrastructure.\ncompanies charts # itop will be used by two companies: Company A which is the service provider \u0026amp; Company B who use their services.\nHere is the Company A agency graph.\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%% flowchart TD subgraph z[Company A Chart - Service Provider] subgraph m[CEO] a[Person A] end subgraph h[Executive Assistant] b[Person B] end subgraph i[Technical Manager] c[Person C] end subgraph j[Network \u0026 Sysadmins] d[Person D] e[Person E] end subgraph k[Work-Study Students] f[Person F] g[Person G] end end m---h m---i i---j i---k style z fill:#fff,stroke:#fff,stroke-width:4px Here is the Company B one.\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%% flowchart TD subgraph z[Company B Chart - Consumer] subgraph a[CEO] b[Person H] end subgraph c[Technical Manager] d[Person I] end subgraph e[Sales Manager] f[Person J] end subgraph g[Head of Logistics] h[Person K] end subgraph i[\"Manufacturing Manager\"] j[Person M] end subgraph k[Assistant] m[Person N] end end a---c a---e c---g c---i e---k style z fill:#fff,stroke:#fff,stroke-width:4px All persons in the two companies will have access to an itop interface (in reality it is not necessary).\nrequirements # Here is the itop hardware recommendations from their documentation.\nActivity Recommendations Tickets/monthUsersCIs\u0026lt;200\u0026lt;20\u0026lt;50k\u0026lt;5k\u0026lt;50\u0026lt;200k\u0026gt;5k\u0026gt;50\u0026gt;200k ServersCPUMemoryMySQL DB sizeAll-in-one2vCPU4Gb10GbWeb+MySQL4vCPU8Gb20GbWeb+MySQL8vCPU16Gb50Gb infrastructure # There is 13 people who will potentially use itop in the two companies combined (\u0026lt; 50). The number of CIs will be under 50'000 \u0026amp; the tickets/month under 200.\nThe all-in-one server will be chose with itop \u0026amp; a MySQL server installed.\nNote For a production use, looking for expandability by choosing the seperate solutions would be a better choice. Here is the network infrastructure that will be used.\ngraph TD subgraph company-b[Company B Network] router-b{Router} switch-b[Network Switch] consumer-pc(Consumer Device) apache-b(Apache Server) end subgraph company-a[Company A Network] router-a{Router} switch-a[Network Switch] itop-server(Debian Machine\n2vCPU 4GB) db-server[(MySQL DB\n10GB)] itop(itop Community) apache-a(Apache Server) end wan{WAN} --- router-a \u0026 router-b router-a ---|192.168.122.0/24| switch-a switch-a ---|192.168.122.212| itop-server itop-server -.- db-server \u0026 itop switch-a ---|192.168.122.111| apache-a router-b ---|192.168.1.0/24| switch-b switch-b ---|192.168.1.1| consumer-pc switch-b ---|192.168.1.2| apache-b The Company A is providing an apache web server from their LAN as a service \u0026amp; monitor an other one from the Company B LAN.\ninstallations # I made an installation scripts for itop community \u0026amp; for a mysql server according to itop requirements.\n(yes, i could saved a lot of time not doing this, but foss)\nBoth scripts are interactive \u0026amp; made for debian - tested on debian 11 \u0026amp; 12, source code is on Github.\nThe itop server installation can be done running the following commands.\nmkdir itop_install \u0026amp;\u0026amp; cd itop_install wget https://raw.githubusercontent.com/xeylou/itop-tour/main/debian-itop-install.sh chmod +x debian-itop-install.sh ./debian-itop-install.sh Here to install the mysql server.\nmkdir mysql_install \u0026amp;\u0026amp; cd mysql_install wget https://raw.githubusercontent.com/xeylou/itop-tour/main/debian-mysql-install.sh chmod +x debian-mysql-install.sh ./debian-mysql-install.sh An external mysql database can be used without this installation script, an full privilieged user for this database is needed to use itop.\nThe installation can be resumed at http://192.168.122.212.\n(highlighted forms are clicked/changed values)\nThe warning says the used php version (latest) is not tested for this itop version by Combodo. (not appening with debian 11 because its repositories has an older php version) The Server Name is localhost because the itop instance \u0026amp; the mysql server are on the same host - can be replaced by the ip address of the external mysql server if using the seperate solution.\nThe Login \u0026amp; the Password was created during the debian-mysql-install.sh script process - asked at the beginning -. The database name found was also created during the installation process. Person C will have admin privilieges for this itop instance, since it is the Technical Manager. (can add more admins after)\nThe Language set is for this user only. Here the Default Language for all users can be changed. Can also be changed by individual users after deploying. Since the Company A acts as a service provider, the second option is chose. The first option should be kept if delivering IT services to company departements. Simple Ticket Management can be chose to get rid of SLTs \u0026amp; SLAs. The Customer Portal is the itop interface but reagenced for users tickets. If not chose, tickets should be created using command-lines method or the rest api. cmdb confirguration # The cmdb (organizations, persons, teams etc.) needs to be configured first.\nDepending on the company/ies \u0026amp; the infrastructure/s sizes, it could take some time to populate.\nExporting \u0026amp; importing csv files is a great option to configure it quickly. Here is a video from itop explaining how to do so (i still think putting mine will be worse).\nSynchronizing csv files (itop server \u0026amp; an editor side) can also be done to avoid entering each modification manually, scheduling this task to. ELDAP \u0026amp; AD services can also be used instead of this method.\nManual objects implementation \u0026amp; modification can also be done. A rest api is also present for external use cases.\nitsm overview # The itsm is following the cmdb configuration: users created, teams, organizations, services, contracts etc.\nExternal User profile for the iTop User object have a dashboard to create requests according to purchased services.\nThe user can change his Phone number, Location according to his company\u0026rsquo;s locations in the cmdb, the language to use or his profile picture.\nIt can also rename his function inside the company or change his password.\nWhen entering in New request, according to default objects, the services can be defined in sub-services to help the end user.\nThe provider has the itop dashboard (administrators like person c or other profiles) to interract with created tickets.\nTo avoid putting a gigantic amount of screenshots to show how the itsm works, here is itop video for that (better than the ones i made i think\u0026hellip;).\nA designer is available to custom the itsm interfaces.\nmonitoring # Once the cmdb is configured, links can be done between hardware \u0026amp; Application Services for the end users.\nThey are created using Contracts (Customer \u0026amp; Provider) with SLAs etc.\nSince itop is an itsm \u0026amp; cmdb solution, it doesn\u0026rsquo;t have a proper monitoring system.\nHowever, itop can integrate nagios for incident management (creating tickets).\nclose # It required a lot of time \u0026amp; effort to make my hands on, it\u0026rsquo;s not incredibly difficult - depends on what you usually do - but demanding. (compare to the nagios experience i have)\nTo keep their customers\u0026rsquo; time, they do bootcamps for 140$/h \u0026amp; have paid consultants.\nFor a production or business use, customers may pay for the professional or business itop solutions with consultants to help them integrating itop \u0026amp; keep a lot of time.\nI think one or more IT guys are needed to implement, maintain \u0026amp; using it (expecially with oql querries \u0026amp; various technos not covered).\nI saw on forums itop could implement customers\u0026rsquo; itsm for their need, but the discussion stopped here.\nI also like their blog.\nI am happy that i have found a way to understand itop \u0026amp; the surroundings properly \u0026amp; alone in a week, i hope so.\n","date":"2023-08-05","externalUrl":null,"permalink":"/posts/itop-tour/","section":"Posts","summary":"combodo itop tour \u0026amp; creating a living","title":"combodo itop tour","type":"posts"},{"content":" understanding Nagios principles \u0026amp; deploying\na monitoring infrastructure using custom scripts introduction # For my work-study, i immersed myself in understanding Nagios.\nHere i expose what i\u0026rsquo;ve learned \u0026amp; what i\u0026rsquo;ve done with it.\nI\u0026rsquo;d be extremely grateful if you\u0026rsquo;d consider correcting me if i said something wrong.\nThis article mainly talks about Nagios as the Nagios Core solution.\npresentation # Nagios Core is an open source, widely used monitoring tool for hosts, applications \u0026amp; services.\nThe company behind Nagios, Nagios Enterprises, makes profit by selling solutions around Nagios Core.\nThey provide non-free solutions to make the Nagios Core utilisation simplified, such as a more sophisticated dashboard - Nagios XI, or a better network implementation - Nagios Network Analyzer.\nThose solutions are improvers for Nagios Core, highly prefered for production use but not mandatory.\nside notes # Nagios Core source code can be found on Github, it is written in C language.\nYou may also consider, regarding your deontology or your use case, using your own metrics collector to serve them into a dashboard - using Prometheus \u0026amp; Grafana for example.\nnagios principles # Covering the basics of Nagios Core according to monitoring a windows host \u0026amp; a linux host with their services.\nfundamentals # Nagios Core needs to be installed on a host, bare metal or in a vm - no official docker image available.\nTo monitor hosts, the Nagios server will execute a sequence of commands at a sheduled interval \u0026amp; will define the state of the monitored host/service according to the output of the sequence.\nThis series of checks can be customised according to what service to monitor.\nA simple \u0026amp; in use example can be the default HOST STATUS check by Nagios: the Nagios server send an echo request to the host: if it receive an echo reply back -\u0026gt; HOST STATUS: UP, else -\u0026gt; HOST STATUS: DOWN.\nApart from well-known protocols, to monitor the largest amount of services, Nagios lets its community post their own Projects.\nSince then, the community created \u0026amp; shared their free plugins \u0026amp; add-ons to monitor their needed little-known services - all in their Nagios Exchange platform.\nplugins # The commands used to monitor services are called plugins.\nPlugins are located in /usr/local/nagios/libexec/ with their name starting with check_*.\nThese plugins can be used as executable files to quickly check the status of a service.\nThose actions are parts of \u0026ldquo;active monitoring\u0026rdquo;, which is very usefull during pre-production tests.\nExample of an active check with check_http plugin.\n/usr/local/nagios/libexec/check_http -h display the check_http\nplugin help page\nFollowing the check_http help page, this check can be executed on a host to check its http response.\n/usr/local/nagios/libexec/check_http -H 192.168.122.15 HTTP OK: HTTP/1.1 200 OK - 10975 bytes in 0.002 second response time |time=0.001620s;;;0.000000 size=10975B;;;0\nadd-ons # Plugins only monitor external metrics.\nTo monitor internal ones like system utilization (cpu load, ram, disk usage etc.), Nagios use what they call add-ons.\nAdd-ons are splited software, an agent on the monitored host waiting for a gathering query \u0026amp; an executable file on the nagios server to communicate with the agent api.\nThose add-ons often use tokens or passwords to verify the authenticity of the nagios server.\nFrom the Nagios server side, the add-ons will be used as executable files like plugins are.\nnagios configuration files # Nagios *.cfg configuration files are located in /usr/local/nagios/etc/.\n. ├── cgi.cfg ├── htpasswd.users ├── nagios.cfg ├── ressource.cfg └── objects ├── commands.cfg ├── contacts.cfg ├── localhost.cfg ├── printer.cfg ├── switch.cfg ├── templates.cfg ├── timeperiodes.cfg └── windows.cfg Since they are well documented inside \u0026amp; on the web, i\u0026rsquo;ll just outline their purpose.\nThe nagios.cfg is the main Nagios configuration file.\nIt contains informations such as log files location, individual or grouped hosts configuration files locations, services check interval \u0026amp; more.\nA standard htpasswd.users is created in the installation process \u0026amp; define the Nagios users \u0026amp; passwords.\nCGIs check their cgi.cfg configuration file to gather user \u0026amp; groups permissions. It also contains the path for Nagios frontend files.\nressource.cfg define macros used in hosts configuration files for sensitive informations. Also provides plugins paths - handy for moving plugins or adding custom ones.\n(\u0026ldquo;sensitive informations\u0026rdquo; e.g.: to monitor non public metrics on a database, a username \u0026amp; a password is needed at some point)\nConfiguration files inside the objects directory are used to define commands, contacts, hosts, services etc. (more on that in hosts configuration files)\nhosts configuration files # Nagios monitor hosts by scheduling plugins tasks or calling add-ons \u0026amp; reporting the results on a control panel.\nTo define what checks should be made on which host, Nagios use Object Configuration Files.\nThese are *.cfg configuration files in which you define the host informations \u0026amp; the check_ commands that should be used.\nIt is recommended to create directories according to your kind of hosts - create a folder for all windows hosts, linux servers etc.\nOtherwise, configuration files can be manually added to the nagios.cfg like the localhost.cfg is by default.\ndeployment # Demonstration of how nagios works.\nDeploying an infrastructure based on the system monitoring of a server or client Windows Host \u0026amp; a Debian Host.\nnetwork plan # N a g i o s S e 1 r 9 v 2 e . r 1 6 8 . 1 2 2 . 2 0 3 N e W t i w n o d r o k w s S w H i 1 o t 9 s c 2 t h . 1 6 8 . 1 2 2 . 5 3 D e b i a n H 1 o 9 s 2 t . 1 6 8 . 1 2 2 . 1 6 5 windows host # Add-ons are needed to monitor hosts system activity.\nA lot of agents are available for windows \u0026amp; linux hosts. Nagios Cross-Platform Agent (NCPA) will be used because it is still recently maintained (by Nagios Enterprises).\n(note: for community maintained one, NSclient++ for windows \u0026amp; linux seems to be a good choice)\nTo install NCPA, start by downloading \u0026amp; executing the agent installer on the host.\nDownload the latest NCPA agent installer Here are the simple following steps for the install.\n(highlighted forms are clicked/changed values)\nBind IP default value is 0.0.0.0 to accept every ip address who request metrics - replaced by the Nagios Server ip address.\nPort \u0026amp; Token can be changed.\ndebian host # NCPA will also be used for the debian host so that the check commands syntax will be the same for both hosts.\nI made an installation script for the debian agent, source code is on Github for debian 11 \u0026amp; 12.\nmkdir testing \u0026amp;\u0026amp; cd testing wget https://raw.githubusercontent.com/xeylou/nagios-introduction/main/debian-ncpa-install.sh chmod +x debian-ncpa-install.sh ./debian-ncpa-install.sh By using it, it will ask you the Nagios Server ip address \u0026amp; a custom token so that only it can gather metrics.\nChanges are made by changing the allowed_hosts \u0026amp; the community_string variables in /usr/local/ncpa/etc/ncpa.cfg.\nFor other linux distributions than debian, the ncpa download page can be usefull.\nThe default 5693 port is used to transfer metrics.\nnagios server # The Nagios Server is in my case a Debian machine that host Nagios Core \u0026amp; the Nagios Plugins.\nI made an installation script for those by compiling code from source - tested on debian 11 \u0026amp; 12.\nmkdir testing \u0026amp;\u0026amp; cd testing wget https://raw.githubusercontent.com/xeylou/nagios-introduction/main/debian-nagios-install.sh chmod +x debian-nagios-install.sh ./debian-nagios-install.sh Nagios web interface can be reach at http://192.168.122.203/nagios with the username nagiosadmin \u0026amp; the password given at the beginning of the installation.\nCan check the connectivity to the agent on the windows host using the check_ncpa add-on command.\n/usr/local/nagios/libexec/check_ncpa.py -H 192.168.122.53 -t \u0026#39;windows-host\u0026#39; -P 5693 -M system/agent_version OK: Agent_version was [\u0026lsquo;2.4.1\u0026rsquo;]\nFor the debian one (changing values).\n/usr/local/nagios/libexec/check_ncpa.py -H 192.168.122.165 -t \u0026#39;debian-host\u0026#39; -P 5693 -M system/agent_version OK: Agent_version was [\u0026lsquo;2.4.1\u0026rsquo;]\n(note: the -H parameter is the host\u0026rsquo;s hostname or its ip address, -t is for the token created by the host during the agent installation process, -P the used port \u0026amp; -M the called value)\nExample of active monitoring of the cpu load for both (same syntax).\nRefer to the ncpa documentation to gather other metrics.\n/usr/local/nagios/libexec/check_ncpa.py -H 192.168.122.53 -t \u0026#39;windows-host\u0026#39; -P 5693 -M cpu/percent -w 20 -c 40 -q \u0026#39;aggregate=avg\u0026#39; OK: Percent was 4.70 % | \u0026lsquo;percent\u0026rsquo;=4.70%;20;40;\nHere on the debian host.\n/usr/local/nagios/libexec/check_ncpa.py -H 192.168.122.165 -t \u0026#39;debian-host\u0026#39; -P 5693 -M cpu/percent -w 20 -c 40 -q \u0026#39;aggregate=avg\u0026#39; OK: Percent was 0.00 % | \u0026lsquo;percent\u0026rsquo;=0.00%;20;40;\nTo add the hosts to the nagios web interface for passive monitoring: the Nagios Server requires their .cfg configuration files.\nStarting by creating two directories to organise them: windows-hosts \u0026amp; debian-hosts (see hosts configuration files recommendation).\nmkdir /usr/local/nagios/etc/windows-hosts mkdir /usr/local/nagios/etc/debian-hosts Added them to the /usr/local/nagios/etc/nagios.cfg nagios configuration file.\n47 48 49 50 51 52 53 54 55 56 # You can also tell Nagios to process all config files (with a .cfg # extension) in a particular directory by using the cfg_dir # directive as shown below: cfg_dir=/usr/local/nagios/etc/windows-hosts cfg_dir=/usr/local/nagios/etc/debian-hosts #cfg_dir=/usr/local/nagios/etc/servers #cfg_dir=/usr/local/nagios/etc/printers #cfg_dir=/usr/local/nagios/etc/switches #cfg_dir=/usr/local/nagios/etc/routers These files define the hosts inside define host and its services to monitor.\nHere is an example of the define host used for monitoring the debian host in /usr/local/nagios/debian-hosts/debian-host.cfg.\n1define host { 2 host_name debian-host 3 address 192.168.122.165 4 check_command check_ncpa!-t \u0026#39;debian-host\u0026#39; -P 5693 -M system/agent_version 5 max_check_attempts 5 6 check_interval 5 7 retry_interval 1 8 check_period 24x7 9 contacts nagiosadmin 10 notification_interval 60 11 notification_period 24x7 12 notifications_enabled 1 13 register 1 14} host_name is used for nagios to identify the host on its interface. The check_command defines the checked parameter for the HOST STATUS.\nHere is an example to implement the cpu load check to the configuration file by defining a service to monitor.\n16define service { 17 host_name debian-host 18 service_description CPU Load 19 check_command check_ncpa!-t \u0026#39;debian-host\u0026#39; -P 5693 -M cpu/percent -w 20 -c 40 -q \u0026#39;aggregate=avg\u0026#39; 20 max_check_attempts 5 21 check_interval 5 22 retry_interval 1 23 check_period 24x7 24 notification_interval 60 25 notification_period 24x7 26 contacts nagiosadmin 27 register 1 28} A command can be used to check errors in your *.cfg configuration files before restarting nagios service.\nHere is an example with the debian host *.cfg file.\n/usr/local/nagios/bin/nagios -v /usr/local/nagios/etc/debian-hosts/debian-host.cfg Finishing by restarting Nagios service to make changes take effect.\nsystemctl restart nagios overview # Once logged into the nagios web interface, the hosts status can be see in the Hosts section of the Current Status.\nThe services status are available in the Services one.\nclose # I found the nagios documentation quite well explained (using \u0026amp; compiling from source) although sometimes obsolete - relating to discontinued stuff or frustrating - some requirements missing from current repos.\nNagios Core is very very old, when doing my searching i was often finding myself reading forums posts from 2007-2009.\nAnother thought on Nagios Core is that its \u0026ldquo;unalive\u0026rdquo; today. Near nothing need to be changed in the code, because it does what it said on the tin.\nThe only things its team wants to work on now might be their cost solutions. However it\u0026rsquo;s for mission criticial tasks or companies wanted stuff that people charge off.\nThe real power is in the nagiosXI from a reddit user, and i found it sad from.\nOtherwise, i like nagios core flexibility by its check commands \u0026amp; its community that is still alive \u0026amp; contribute to plugins \u0026amp; add-ons.\n","date":"2023-07-25","externalUrl":null,"permalink":"/posts/nagios-introduction/","section":"Posts","summary":"understanding Nagios principles \u0026amp; deploying","title":"nagios introduction","type":"posts"},{"content":" Note i try to keep this page as up to date as possible\nyou can always contact me if the last update is too old Work # i am a second-grade Network \u0026amp; Telecommunication bachelor student at University of Pau and the Adour Region\ni do a work-study as an apprentice Network \u0026amp; System Administrator for a french IT service delivery company\nFreetime # exploring \u0026amp; creating Github repos about IT related stuff\n","date":"2023-07-19","externalUrl":null,"permalink":"/now/","section":"","summary":"Note i try to keep this page as up to date as possible","title":"Now","type":"page"},{"content":"","date":"0001-01-01","externalUrl":null,"permalink":"/authors/","section":"Authors","summary":"","title":"Authors","type":"authors"},{"content":"","date":"0001-01-01","externalUrl":null,"permalink":"/categories/","section":"Categories","summary":"","title":"Categories","type":"categories"},{"content":"","date":"0001-01-01","externalUrl":null,"permalink":"/topics/","section":"Topics","summary":"","title":"Topics","type":"topics"}]